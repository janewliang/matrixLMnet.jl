var documenterSearchIndex = {"docs":
[{"location":"functions/#Index","page":"Types and Functions","title":"Index","text":"","category":"section"},{"location":"functions/","page":"Types and Functions","title":"Types and Functions","text":"","category":"page"},{"location":"functions/#Description","page":"Types and Functions","title":"Description","text":"","category":"section"},{"location":"functions/","page":"Types and Functions","title":"Types and Functions","text":"Modules = [MatrixLMnet]","category":"page"},{"location":"functions/#MatrixLMnet.Mlmnet_bic","page":"Types and Functions","title":"MatrixLMnet.Mlmnet_bic","text":"Mlmnet_bic(MLMNet, lambdas, alphas, data)\n\nType for storing the results of running BIC validation for mlmnet\n\n\n\n\n\n","category":"type"},{"location":"functions/#MatrixLMnet.Mlmnet_cv","page":"Types and Functions","title":"MatrixLMnet.Mlmnet_cv","text":"Mlmnet_cv(MLMNets::Array{Mlmnet,1} , lambdas::Array{Float64,1}, alphas::Array{Float64,1}, data::RawData, rowFolds::Array{Array,1} , colFolds::Array{Array,1} )\n\nType for storing the results of running cross-validation for mlmnet\n\n\n\n\n\n","category":"type"},{"location":"functions/#MatrixLMnet.admm!-Tuple{AbstractMatrix{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}, Float64, Float64, AbstractMatrix{Float64}, AbstractVector{Int64}, AbstractVector{Int64}, BitMatrix, Any, Vararg{AbstractMatrix{Float64}, 4}}","page":"Types and Functions","title":"MatrixLMnet.admm!","text":"admm!(X::AbstractArray{Float64,2}, Y::AbstractArray{Float64,2}, \n           Z::AbstractArray{Float64,2}, lambda::Float64, alpha::Float64,\n           B::AbstractArray{Float64,2}, \n           regXidx::AbstractArray{Int64,1}, \n           regZidx::AbstractArray{Int64,1}, reg::BitArray{2}, norms, \n           Qx::AbstractArray{Float64,2}, Qz::AbstractArray{Float64,2}, \n           U::AbstractArray{Float64,2}, L::AbstractArray{Float64,2}; \n           isVerbose::Bool=true, stepsize::Float64=0.01, \n           rho::Float64=1.0, setRho::Bool=true, \n           thresh::Float64=10.0^(-7), maxiter::Int=10^10, \n           tau_incr::Float64=2.0, tau_decr::Float64=2.0, mu::Float64=10.0)\n\nPerforms ADMM. \n\nArguments\n\nX = 2d array of floats consisting of the row covariates, with all  categorical variables coded in appropriate contrasts\nY = 2d array of floats consisting of the multivariate response\nZ = 2d array of floats consisting of the column covariates, with all  categorical variables coded in appropriate contrasts\nlambda = lambda penalty, a floating scalar\nalpha = parameter (ϵ[0, 1]) determining the mix of penalties between L1 and L2\nB = 2d array of floats consisting of starting coefficient estimates\nregXidx = 1d array of indices corresponding to regularized X covariates\nregZidx = 1d array of indices corresponding to regularized Z covariates\nreg = 2d array of bits, indicating whether or not to regularize each of the  coefficients\nnorms = 2d array of floats consisting of the norms corresponding to each  coefficient or nothing\nQx = 2d array of floats consisting of the eigenvectors of X\nQz = 2d array of floats consisting of the eigenvectors of Z\nU = 2d array of floats consisting of the transformed Y matrix\nL = 2d array of floats consisting of the kronecker product of the  eigenvalues of X and Z\n\nKeyword arguments\n\nisVerbose = boolean flag indicating whether or not to print messages.   Defaults to true. \nstepsize = float; step size for updates (irrelevant for ADMM).  Defaults to 0.01. \nrho = float; parameter that controls ADMM tuning. Defaults to 1.0. \nsetRho = boolean flag indicating whether the ADMM tuning parameter rho  should be calculated. Defaults to true.\nthresh = threshold at which the coefficients are considered to have  converged, a floating scalar. Defaults to 10^(-7). \nmaxiter = maximum number of update iterations. Defaults to 10^10. \ntau_incr = float; parameter that controls the factor at which rho increases.  Defaults to 2.0. \ntau_decr = float; parameter that controls the factor at which rho decreases.  Defaults to 2.0. \nmu = float; parameter that controls the factor at which the primal and dual  residuals should be within each other. Defaults to 10.0. \n\nValue\n\nNone; updates coefficients in place\n\nSome notes\n\nConvergence is determined as when the log ratio of the current and previous  criteria is less than the threshold thresh. \n\nrho controls ADMM tuning and can be specified by the user. \n\n\n\n\n\n","category":"method"},{"location":"functions/#MatrixLMnet.backtransform!-NTuple{8, AbstractMatrix{Float64}}","page":"Types and Functions","title":"MatrixLMnet.backtransform!","text":"backtransform!(B::AbstractArray{Float64,2}, \n                    meansX::AbstractArray{Float64,2}, \n                    meansZ::AbstractArray{Float64,2}, \n                    normsX::AbstractArray{Float64,2}, \n                    normsZ::AbstractArray{Float64,2}, \n                    Y::AbstractArray{Float64,2}, \n                    Xold::AbstractArray{Float64,2}, \n                    Zold::AbstractArray{Float64,2})\n\nBack-transform coefficient estimates B in place if X and Z were standardized  prior to the estimation– when both X and Z include intercept columns. \n\nArguments\n\nB = 2d array of coefficient estimates B\nmeansX = 2d array of column means of X, obtained prior to standardizing X\nmeansZ = 2d array of column means of Z, obtained prior to standardizing Z\nnormsX = 2d array of column norms of X, obtained prior to standardizing X\nnormsZ = 2d array of column norms of Z, obtained prior to standardizing Z\nY = 2d array of response matrix Y\nXold = 2d array row covariates X prior to standardization\nZold = 2d array column covariates Z prior to standardization\n\nValue\n\nNone; back-transforms B in place\n\n\n\n\n\n","category":"method"},{"location":"functions/#MatrixLMnet.backtransform!-Tuple{AbstractArray{Float64, 4}, Bool, Bool, Vararg{AbstractMatrix{Float64}, 4}}","page":"Types and Functions","title":"MatrixLMnet.backtransform!","text":"backtransform!(B::AbstractArray{Float64,4}, \n                    addXIntercept::Bool, addZIntercept::Bool, \n                    meansX::AbstractArray{Float64,2}, \n                    meansZ::AbstractArray{Float64,2}, \n                    normsX::AbstractArray{Float64,2}, \n                    normsZ::AbstractArray{Float64,2})\n\nBack-transform coefficient estimates B in place if X and Z were standardized  prior to the estimation– when not including intercept columns for either X  or Z. \n\nArguments\n\nB = 4d array of coefficient estimates\naddXIntercept = boolean flag indicating whether or not to X has an  intercept column\naddZIntercept = boolean flag indicating whether or not to Z has an  intercept column\nmeansX = 2d array of column means of X, obtained prior to standardizing X\nmeansZ = 2d array of column means of Z, obtained prior to standardizing Z\nnormsX = 2d array of column norms of X, obtained prior to standardizing X\nnormsZ = 2d array of column norms of Z, obtained prior to standardizing Z\n\nValue\n\nNone; back-transforms B in place. \n\nSome notes\n\nB is a 4d array in which each coefficient matrix is stored along the third and fourth  dimension. \n\n\n\n\n\n","category":"method"},{"location":"functions/#MatrixLMnet.backtransform!-Tuple{AbstractArray{Float64, 4}, Vararg{AbstractMatrix{Float64}, 7}}","page":"Types and Functions","title":"MatrixLMnet.backtransform!","text":"backtransform!(B::AbstractArray{Float64,4}, \n                    meansX::AbstractArray{Float64,2}, \n                    meansZ::AbstractArray{Float64,2}, \n                    normsX::AbstractArray{Float64,2}, \n                    normsZ::AbstractArray{Float64,2}, \n                    Y::AbstractArray{Float64,2}, \n                    Xold::AbstractArray{Float64,2}, \n                    Zold::AbstractArray{Float64,2})\n\nBack-transform coefficient estimates B in place if X and Z were standardized  prior to the estimation– when both X and Z include intercept columns. \n\nArguments\n\nB = 4d array of coefficient estimates B\nmeansX = 2d array of column means of X, obtained prior to standardizing X\nmeansZ = 2d array of column means of Z, obtained prior to standardizing Z\nnormsX = 2d array of column norms of X, obtained prior to standardizing X\nnormsZ = 2d array of column norms of Z, obtained prior to standardizing Z\nY = 2d array of response matrix Y\nXold = 2d array row covariates X prior to standardization\nZold = 2d array column covariates Z prior to standardization\n\nValue\n\nNone; back-transforms B in place\n\nSome notes\n\nB is a 4d array in which each coefficient matrix is stored along the third and fourth dimension. \n\n\n\n\n\n","category":"method"},{"location":"functions/#MatrixLMnet.backtransform!-Tuple{AbstractMatrix{Float64}, Bool, Bool, Vararg{AbstractMatrix{Float64}, 4}}","page":"Types and Functions","title":"MatrixLMnet.backtransform!","text":"backtransform!(B::AbstractArray{Float64,2}, \n                    addXIntercept::Bool, addZIntercept::Bool, \n                    meansX::AbstractArray{Float64,2}, \n                    meansZ::AbstractArray{Float64,2}, \n                    normsX::AbstractArray{Float64,2}, \n                    normsZ::AbstractArray{Float64,2})\n\nBack-transform coefficient estimates B in place if X and Z were standardized  prior to the estimation– when not including intercept columns for either X  or Z. \n\nArguments\n\nB = 2d array of coefficient estimates B\naddXIntercept = boolean flag indicating whether or not to X has an  intercept column\naddZIntercept = boolean flag indicating whether or not to Z has an  intercept column\nmeansX = 2d array of column means of X, obtained prior to standardizing X\nmeansZ = 2d array of column means of Z, obtained prior to standardizing Z\nnormsX = 2d array of column norms of X, obtained prior to standardizing X\nnormsZ = 2d array of column norms of Z, obtained prior to standardizing Z\n\nValue\n\nNone; back-transforms B in place\n\n\n\n\n\n","category":"method"},{"location":"functions/#MatrixLMnet.calc_avg_mse-Tuple{Mlmnet_cv}","page":"Types and Functions","title":"MatrixLMnet.calc_avg_mse","text":"calc_avg_mse(MLMNet_cv::Mlmnet_cv)\n\nCalculates average test MSE across folds. \n\nArguments\n\nMLMNetcv = MLMNetcv object\n\nValue\n\n2d array of floats\n\n\n\n\n\n","category":"method"},{"location":"functions/#MatrixLMnet.calc_avg_prop_zero-Tuple{Mlmnet_cv}","page":"Types and Functions","title":"MatrixLMnet.calc_avg_prop_zero","text":"calc_avg_prop_zero(MLMNet_cv::Mlmnet_cv)\n\nCalculates average proportion of zero interaction coefficients across folds. \n\nArguments\n\nMLMNetcv = MLMNetcv object\n\nValue\n\n1d array of floats\n\n\n\n\n\n","category":"method"},{"location":"functions/#MatrixLMnet.calc_bic-Tuple{Mlmnet}","page":"Types and Functions","title":"MatrixLMnet.calc_bic","text":"calc_bic(MLMNet::Mlmnet)\n\nCalculates BIC for each model according to the lambda-alpha  pair parameter. \n\nArguments\n\nMLMNets = Mlmnet object resulting from mlmnet() function.\n\nValue\n\n2d array of floats with dimensions equal to the number of lambdas by the  number of alphas. \n\n\n\n\n\n","category":"method"},{"location":"functions/#MatrixLMnet.calc_grad!-NTuple{4, AbstractMatrix{Float64}}","page":"Types and Functions","title":"MatrixLMnet.calc_grad!","text":"calc_grad!(grad::AbstractArray{Float64,2}, \n                X::AbstractArray{Float64,2}, \n                Z::AbstractArray{Float64,2}, \n                resid::AbstractArray{Float64,2})\n\nCalculate gradient in place\n\nArguments\n\ngradient = 2d array of floats consisting of the gradient, to be updated in  place\nX = 2d array of floats consisting of the row covariates, standardized as  necessary\nZ = 2d array of floats consisting of the column covariates, standardized  as necessary\nresid = 2d array of floats consisting of the residuals\n\nValue\n\nNone; updates gradient in place. \n\n\n\n\n\n","category":"method"},{"location":"functions/#MatrixLMnet.calc_grad-Tuple{AbstractVector{Float64}, AbstractVector{Float64}, AbstractMatrix{Float64}}","page":"Types and Functions","title":"MatrixLMnet.calc_grad","text":"calc_grad!(Xi::AbstractArray{Float64,1}, Zj::AbstractArray{Float64,1}, \n               resid::AbstractArray{Float64,2})\n\nCalculate gradient at a single coefficient\n\nArguments\n\nXi = 1d array of floats consisting of the row covariates for the  coefficient, standardized as necessary\nZj = 1d array of floats consisting of the column covariates for the  coefficient, standardized as necessary\nresid = 2d array of floats consisting of the residuals\n\nValue\n\nA floating scalar\n\n\n\n\n\n","category":"method"},{"location":"functions/#MatrixLMnet.calc_mse-Tuple{AbstractVector{Mlmnet}, RawData, AbstractVector{Float64}, AbstractVector{Float64}, Vector{Vector{Int64}}, Vector{Vector{Int64}}}","page":"Types and Functions","title":"MatrixLMnet.calc_mse","text":"    calc_mse(MLMNets::AbstractArray{Mlmnet,1}, data::RawData, \n              lambdas::AbstractArray{Float64,1}, \n              alphas::AbstractArray{Float64,1},\n              rowFolds::Array{Array{Int64,1},1}, \n              colFolds::Array{Array{Int64,1},1})\n\nCalculates test MSE for each of the CV folds for each lambda. \n\nArguments\n\nMLMNets = 1d array of Mlmnet objects resulting from running cross validation\ndata = RawData object used to generate MLMNets\nlambdas = 1d array of floats consisting of the total penalties in descending  order. If they are not in descending order, they will be sorted. \nalphas = 1d array of floats consisting of the penalty ratio that  determines the mix of penalties between L1 and L2\nrowFolds = 1d array of arrays containing booleans for the row folds\ncolFolds = 1d array of arrays containing booleans for the column folds\n\nValue\n\n2d array of floats with dimensions equal to the number of lambdas by the  number of folds. \n\n\n\n\n\n","category":"method"},{"location":"functions/#MatrixLMnet.calc_mse-Tuple{Mlmnet}","page":"Types and Functions","title":"MatrixLMnet.calc_mse","text":"    calc_mse(MLMNet::Mlmnet)\n\nCalculates test MSE for each pair of lambda-alpha. \n\nArguments\n\nMLMNet = Mlmnet object\n\nValue\n\nMatrix of floats with dimensions equal to the number of lambdas by the number of alphas.\n\n\n\n\n\n","category":"method"},{"location":"functions/#MatrixLMnet.calc_prop_zero-Tuple{AbstractVector{Mlmnet}, AbstractVector{Float64}, AbstractVector{Float64}}","page":"Types and Functions","title":"MatrixLMnet.calc_prop_zero","text":"calc_prop_zero(MLMNets::AbstractArray{Mlmnet,1}, \n                    lambdas::AbstractArray{Float64,1},\n                    alphas::AbstractArray{Float64,1}; \n                    dig::Int64=12)\n\nCalculates proportion of zero interaction coefficients for each of the CV  folds for each lambda. \n\nArguments\n\nMLMNets = 1d array of Mlmnet objects resulting from running cross validation\nlambdas = 1d array of floats consisting of lambda penalties used to  generate MLMNets\n\nKeyword arguments\n\ndig = integer; digits of precision for zero coefficients. Defaults to 12. \n\nValue\n\n2d array of floats with dimensions equal to the number of lambdas by the  number of folds. \n\n\n\n\n\n","category":"method"},{"location":"functions/#MatrixLMnet.calc_prop_zero-Tuple{Mlmnet}","page":"Types and Functions","title":"MatrixLMnet.calc_prop_zero","text":"calc_prop_zero(MLMNet::Mlmnet; dig::Int64=12)\n\nCalculates proportion of zero interaction coefficients for each of the CV  folds for each lambda. \n\nArguments\n\nMLMNet = Mlmnet object \n\nKeyword arguments\n\ndig = integer; digits of precision for zero coefficients. Defaults to 12. \n\nValue\n\nMatrix of floats with dimensions equal to the number of lambdas by the number of alphas. \n\n\n\n\n\n","category":"method"},{"location":"functions/#MatrixLMnet.cd!-Tuple{AbstractMatrix{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}, Float64, Float64, AbstractMatrix{Float64}, AbstractVector{Int64}, AbstractVector{Int64}, BitMatrix, Any}","page":"Types and Functions","title":"MatrixLMnet.cd!","text":"cd!(X::AbstractArray{Float64,2}, Y::AbstractArray{Float64,2}, \n         Z::AbstractArray{Float64,2}, lambda::Float64, alpha::Float64,\n         B::AbstractArray{Float64,2}, \n         regXidx::AbstractArray{Int64,1}, \n         regZidx::AbstractArray{Int64,1}, reg::BitArray{2}, norms; \n         isVerbose::Bool=true, stepsize::Float64=0.01, \n         isRandom::Bool=true, thresh::Float64=10.0^(-7), \n         maxiter::Int=10^10)\n\nPerforms coordinate descent using either random or cyclic updates. Does NOT  take advantage of the active set; see cd_active!. \n\nArguments\n\nX = 2d array of floats consisting of the row covariates, with all  categorical variables coded in appropriate contrasts\nY = 2d array of floats consisting of the multivariate response\nZ = 2d array of floats consisting of the column covariates, with all  categorical variables coded in appropriate contrasts\nlambda = lambda penalty, a floating scalar\nalpha = parameter (ϵ[0, 1]) determining the mix of penalties between L1 and L2\nB = 2d array of floats consisting of starting coefficient estimates\nregXidx = 1d array of indices corresponding to regularized X covariates\nregZidx = 1d array of indices corresponding to regularized Z covariates\nreg = 2d array of bits, indicating whether or not to regularize each of the  coefficients\nnorms = 2d array of floats consisting of the norms corresponding to each  coefficient or nothing\n\nKeyword arguments\n\nisVerbose = boolean flag indicating whether or not to print messages.   Defaults to true. \nstepsize = float; step size for updates  (irrelevant for coordinate descent). Defaults to 0.01. \nisRandom = boolean flag indicating whether to use random or cyclic updates.  Defaults to true. \nthresh = threshold at which the coefficients are considered to have  converged, a floating scalar. Defaults to 10^(-7). \nmaxiter = maximum number of update iterations. Defaults to 10^10. \n\nValue\n\nNone; updates coefficients in place\n\nSome notes\n\nConvergence is determined as when the log ratio of the current and previous  criteria is less than the threshold thresh. \n\n\n\n\n\n","category":"method"},{"location":"functions/#MatrixLMnet.cd_active!-Tuple{AbstractMatrix{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}, Float64, Float64, AbstractMatrix{Float64}, AbstractVector{Int64}, AbstractVector{Int64}, BitMatrix, Any}","page":"Types and Functions","title":"MatrixLMnet.cd_active!","text":"cd_active!(X::AbstractArray{Float64,2}, Y::AbstractArray{Float64,2}, \n                Z::AbstractArray{Float64,2}, lambda::Float64, alpha::Float64,\n                B::AbstractArray{Float64,2}, \n                regXidx::AbstractArray{Int64,1}, \n                regZidx::AbstractArray{Int64,1}, reg::BitArray{2}, norms; \n                isVerbose::Bool=true, stepsize::Float64=0.01, \n                isRandom::Bool=true, thresh::Float64=10.0^(-7), \n                maxiter::Int=10^10)\n\nPerforms coordinate descent, taking advantage of the active set, using either  random or cyclic updates. \n\nArguments\n\nX = 2d array of floats consisting of the row covariates, with all  categorical variables coded in appropriate contrasts\nY = 2d array of floats consisting of the multivariate response\nZ = 2d array of floats consisting of the column covariates, with all  categorical variables coded in appropriate contrasts\nlambda = lambda penalty, a floating scalar\nalpha = parameter (ϵ[0, 1]) determining the mix of penalties between L1 and L2\nB = 2d array of floats consisting of starting coefficient estimates\nregXidx = 1d array of indices corresponding to regularized X covariates\nregZidx = 1d array of indices corresponding to regularized Z covariates\nreg = 2d array of bits, indicating whether or not to regularize each of the  coefficients\nnorms = 2d array of floats consisting of the norms corresponding to each  coefficient or nothing\n\nKeyword arguments\n\nisVerbose = boolean flag indicating whether or not to print messages.   Defaults to true. \nstepsize = float; step size for updates  (irrelevant for coordinate descent). Defaults to 0.01. \nisRandom = boolean flag indicating whether to use random or cyclic updates.  Defaults to true. \nthresh = threshold at which the coefficients are considered to have  converged, a floating scalar. Defaults to 10^(-7). \nmaxiter = maximum number of update iterations. Defaults to 10^10. \n\nValue\n\nNone; updates coefficients in place\n\nSome notes\n\nConvergence is determined as when the log ratio of the current and previous  criteria is less than the threshold thresh. \n\n\n\n\n\n","category":"method"},{"location":"functions/#MatrixLMnet.coef-Tuple{Mlmnet, Float64, Float64}","page":"Types and Functions","title":"MatrixLMnet.coef","text":"coef(MLMNet::Mlmnet, lambda::Float64, alpha::Float64)\n\nExtract coefficients from Mlmnet object at a given lambda \n\nArguments\n\nMLMNet = Mlmnet object\nlambda = lambda penalty to use, a floating scalar\nalpha = alpha penalty to determine the mix of penalties between L1 and L2 a floating scalar\n\nValue\n\n2d array of coefficients \n\n\n\n\n\n","category":"method"},{"location":"functions/#MatrixLMnet.coef-Tuple{Mlmnet}","page":"Types and Functions","title":"MatrixLMnet.coef","text":"coef(MLMNet::Mlmnet)\n\nExtract all coefficients from Mlmnet object\n\nArguments\n\nMLMNet = Mlmnet object\n\nValue\n\n3d array of coefficients \n\n\n\n\n\n","category":"method"},{"location":"functions/#MatrixLMnet.coef_3d-Tuple{Mlmnet}","page":"Types and Functions","title":"MatrixLMnet.coef_3d","text":"coef_3d(MLMNet::Mlmnet)\n\nExtract coefficients from Mlmnet object as a flattened 2d array\n\nArguments\n\nMLMNet = Mlmnet object\n\nValue\n\n2d array of flattened coefficients, where each column corresponds to a  different lambda and alpha\n\n\n\n\n\n","category":"method"},{"location":"functions/#MatrixLMnet.criterion-Tuple{AbstractMatrix{Float64}, AbstractMatrix{Float64}, Float64, Float64, AbstractVector{Int64}}","page":"Types and Functions","title":"MatrixLMnet.criterion","text":"criterion(B::AbstractArray{Float64,2}, \n               resid::AbstractArray{Float64,2}, \n               lambdaL1::Float64, lambdaL2::Float64, crit_denom::AbstractArray{Int64,1})\n\nCalculate the criterion for the Elastic-net penalty\n\nArguments\n\nB = 2d array of floats consisting of regularized coefficient estimates\nresid = 2d array of floats consisting of the residuals\nlambdaL1 = l1 penalty, a floating scalar\nlambdaL2 = l2 penalty, a floating scalar\ncrit_denom = 1d array of 2 integers, the denominators of the criterion\n\nValue\n\nA floating scalar\n\n\n\n\n\n","category":"method"},{"location":"functions/#MatrixLMnet.findnotin-Tuple{AbstractVector{Int64}, AbstractVector{Int64}}","page":"Types and Functions","title":"MatrixLMnet.findnotin","text":"findnotin(a::AbstractArray{Int64,1}, b::AbstractArray{Int64,1})\n\nReturns elements of b that are not present in a. \n\nArguments\n\na = 1d array of integers\nb = 1d array of integers\n\nValue\n\n1d array of integers\n\n\n\n\n\n","category":"method"},{"location":"functions/#MatrixLMnet.fista!-Tuple{AbstractMatrix{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}, Float64, Float64, AbstractMatrix{Float64}, AbstractVector{Int64}, AbstractVector{Int64}, BitMatrix, Any}","page":"Types and Functions","title":"MatrixLMnet.fista!","text":"fista!(X::AbstractArray{Float64,2}, Y::AbstractArray{Float64,2}, \n            Z::AbstractArray{Float64,2}, \n            lambda::Float64, alpha::Float64,\n            B::AbstractArray{Float64,2}, \n            regXidx::AbstractArray{Int64,1}, \n            regZidx::AbstractArray{Int64,1}, reg::BitArray{2}, norms; \n            isVerbose::Bool=true, stepsize::Float64=0.01, \n            thresh::Float64=10.0^(-7), maxiter::Int=10^10)\n\nPerforms the Elastic-net version FISTA with fixed step size.\n\nArguments\n\nX = 2d array of floats consisting of the row covariates, with all  categorical variables coded in appropriate contrasts\nY = 2d array of floats consisting of the multivariate response\nZ = 2d array of floats consisting of the column covariates, with all  categorical variables coded in appropriate contrasts\nlambda = penalty parameter, a floating scalar\nalpha = parameter (ϵ[0, 1]) determining the mix of penalties between L1 and L2\nB = 2d array of floats consisting of starting coefficient estimates\nregXidx = 1d array of indices corresponding to regularized X covariates\nregZidx = 1d array of indices corresponding to regularized Z covariates\nreg = 2d array of bits, indicating whether or not to regularize each of the  coefficients\nnorms = 2d array of floats consisting of the norms corresponding to each  coefficient or nothing\n\nKeyword arguments\n\nisVerbose = boolean flag indicating whether or not to print messages.   Defaults to true. \nstepsize = float; step size for updates. Defaults to 0.01. \nthresh = threshold at which the coefficients are considered to have  converged, a floating scalar. Defaults to 10^(-7). \nmaxiter = maximum number of update iterations. Defaults to 10^10. \n\nValue\n\nNone; updates coefficients in place\n\nSome notes\n\nConvergence is determined as when the log ratio of the current and previous  criteria is less than the threshold thresh. \n\nThe default method for choosing the fixed step size for fista! is to use the  reciprocal of the product of the maximum eigenvalues of X*transpose(X)  and Z*transpose(Z). This is computed by the mlmnet function when fista!  is passed into the fun argument and setStepSize is set to true. If  setStepSize is set to false, the value of the stepsize argument will be  used as the fixed step size. Note that obtaining the eigenvalues when X  and/or Z are very large may exceed computational limitations. \n\n\n\n\n\n","category":"method"},{"location":"functions/#MatrixLMnet.fista_bt!-Tuple{AbstractMatrix{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}, Float64, Float64, AbstractMatrix{Float64}, AbstractVector{Int64}, AbstractVector{Int64}, BitMatrix, Any}","page":"Types and Functions","title":"MatrixLMnet.fista_bt!","text":"fista_bt!(X::AbstractArray{Float64,2}, Y::AbstractArray{Float64,2}, \n               Z::AbstractArray{Float64,2}, lambda::Float64, alpha::Float64,\n               B::AbstractArray{Float64,2}, \n               regXidx::AbstractArray{Int64,1}, \n               regZidx::AbstractArray{Int64,1}, reg::BitArray{2}, norms; \n               isVerbose::Bool=true, stepsize::Float64=0.01, \n               gamma::Float64=0.5, thresh::Float64=10.0^(-7), \n               maxiter::Int=10^10)\n\nPerforms FISTA with backtracking. \n\nArguments\n\nX = 2d array of floats consisting of the row covariates, with all  categorical variables coded in appropriate contrasts\nY = 2d array of floats consisting of the multivariate response\nZ = 2d array of floats consisting of the column covariates, with all  categorical variables coded in appropriate contrasts\nlambda = lambda penalty, a floating scalar\nalpha = parameter (ϵ[0, 1]) determining the mix of penalties between L1 and L2\nB = 2d array of floats consisting of starting coefficient estimates\nregXidx = 1d array of indices corresponding to regularized X covariates\nregZidx = 1d array of indices corresponding to regularized Z covariates\nreg = 2d array of bits, indicating whether or not to regularize each of the  coefficients\nnorms = 2d array of floats consisting of the norms corresponding to each  coefficient or nothing\n\nKeyword arguments\n\nisVerbose = boolean flag indicating whether or not to print messages.   Defaults to true. \nstepsize = float; step size for updates. Defaults to 0.01. \ngamma = float; multiplying factor for step size backtracking/line search.  Defaults to 0.5. \nthresh = threshold at which the coefficients are considered to have  converged, a floating scalar. Defaults to 10^(-7). \nmaxiter = maximum number of update iterations. Defaults to 10^10. \n\nValue\n\nNone; updates coefficients in place\n\nSome notes\n\nConvergence is determined as when the log ratio of the current and previous  criteria is less than the threshold thresh. \n\nSpecifying a good starting step size (stepsize) and multiplying factor  (gamma) in the mlmnet function when fista_bt! is passed into the fun  argument can be difficult. Shrinking the step size too gradually can result  in slow convergence. Doing so too quickly can cause the criterion to diverge.  We have found that setting stepsize to 0.01 often works well in practice;  choice of gamma appears to be less consequential. \n\n\n\n\n\n","category":"method"},{"location":"functions/#MatrixLMnet.fitted-Tuple{Mlmnet, Float64, Float64}","page":"Types and Functions","title":"MatrixLMnet.fitted","text":"fitted(MLMNet::Mlmnet, lambda::Float64, alpha::Float64)\n\nCalculate fitted values of an Mlmnet object, given a lambda \n\nArguments\n\nMLMNet = Mlmnet object\nlambda = lambda penalty to use, a floating scalar\nalpha = alpha penalty to determine the mix of penalties between L1 and L2 a floating scalar\n\nValue\n\n2d array of fitted values\n\n\n\n\n\n","category":"method"},{"location":"functions/#MatrixLMnet.fitted-Tuple{Mlmnet}","page":"Types and Functions","title":"MatrixLMnet.fitted","text":"fitted(MLMNet::Mlmnet)\n\nCalculate fitted values of an Mlmnet object\n\nArguments\n\nMLMNet = Mlmnet object\n\nValue\n\n3d array of fitted values\n\n\n\n\n\n","category":"method"},{"location":"functions/#MatrixLMnet.get_func-Tuple{String}","page":"Types and Functions","title":"MatrixLMnet.get_func","text":"get_func(method::String)\n\nReturn actual module function name according to method name according to a dictionnary.\n\nArguments\n\nmethod = String describing selected method. The method can be \"ista\",\n\n\"fista\", \"fista_bt\" or \"admm\".\n\nValue\n\nA function\n\n\n\n\n\n","category":"method"},{"location":"functions/#MatrixLMnet.inner_update_cd!-Tuple{Int64, Int64, AbstractMatrix{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}, Float64, BitMatrix}","page":"Types and Functions","title":"MatrixLMnet.inner_update_cd!","text":"inner_update_cd!(i::Int64, j::Int64, B::AbstractArray{Float64,2}, \n                      resid::AbstractArray{Float64,2},\n                      X::AbstractArray{Float64,2}, \n                      Z::AbstractArray{Float64,2}, \n                      norms::AbstractArray{Float64,2}, lambda::Float64, \n                      reg::BitArray{2})\n\nUpdates a single coefficient estimate in place (to be called by  update_cd_cyclic!, update_cd_random!, update_cd_active_cyclic!, or  update_cd_active_random!) when X and Z are not standardized.\n\nArguments\n\ni = row index of the coefficient to update\nj = column index of the coefficient to update\nB = 2d array of floats consisting of coefficient estimates\nresid = 2d array of floats consisting of the residuals\nX = 2d array of floats consisting of the row covariates, with all  categorical variables coded in appropriate contrasts\nZ = 2d array of floats consisting of the column covariates, with all  categorical variables coded in appropriate contrasts\nnorms = 2d array of floats consisting of the norms corresponding to each  coefficient\nlambda = lambda penalty, a floating scalar\nreg = 2d array of bits, indicating whether or not to regularize each of the  coefficients\n\nValue\n\nNone; updates a coefficient in place\n\n\n\n\n\n","category":"method"},{"location":"functions/#MatrixLMnet.inner_update_cd!-Tuple{Int64, Int64, AbstractMatrix{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}, Nothing, Float64, BitMatrix}","page":"Types and Functions","title":"MatrixLMnet.inner_update_cd!","text":"inner_update_cd!(i::Int64, j::Int64, B::AbstractArray{Float64,2}, \n                      resid::AbstractArray{Float64,2}, \n                      X::AbstractArray{Float64,2}, \n                      Z::AbstractArray{Float64,2}, \n                      norms::Nothing, lambda::Float64, reg::BitArray{2})\n\nUpdates a single coefficient estimate in place (to be called by  update_cd_cyclic!, update_cd_random!, update_cd_active_cyclic!, or  update_cd_active_random!) when X and Z are both standardized.\n\nArguments\n\ni = row index of the coefficient to update\nj = column index of the coefficient to update\nB = 2d array of floats consisting of coefficient estimates\nresid = 2d array of floats consisting of the residuals\nX = 2d array of floats consisting of the row covariates, with all  categorical variables coded in appropriate contrasts\nZ = 2d array of floats consisting of the column covariates, with all  categorical variables coded in appropriate contrasts\nnorms = nothing\nlambda = lambda penalty, a floating scalar\nreg = 2d array of bits, indicating whether or not to regularize each of the  coefficients\n\nValue\n\nNone; updates a coefficient in place\n\n\n\n\n\n","category":"method"},{"location":"functions/#MatrixLMnet.ista!-Tuple{AbstractMatrix{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}, Float64, Float64, AbstractMatrix{Float64}, AbstractVector{Int64}, AbstractVector{Int64}, BitMatrix, Any}","page":"Types and Functions","title":"MatrixLMnet.ista!","text":"istaNet!(X::AbstractArray{Float64,2}, Y::AbstractArray{Float64,2}, \n           Z::AbstractArray{Float64,2}, lambda::Float64, alpha::Float64, \n           B::AbstractArray{Float64,2}, \n           regXidx::AbstractArray{Int64,1}, \n           regZidx::AbstractArray{Int64,1}, reg::BitArray{2}, norms; \n           isVerbose::Bool=true, stepsize::Float64=0.01, \n           thresh::Float64=10.0^(-7), maxiter::Int=10^10)\n\nPerforms the Elastic-net version ISTA with fixed step size.\n\nArguments\n\nX = 2d array of floats consisting of the row covariates, with all  categorical variables coded in appropriate contrasts\nY = 2d array of floats consisting of the multivariate response\nZ = 2d array of floats consisting of the column covariates, with all  categorical variables coded in appropriate contrasts\nlambda = penalty parameter, a floating scalar\nalpha = parameter (ϵ[0, 1]) determining the mix of penalties between L1 and L2\nB = 2d array of floats consisting of starting coefficient estimates\nregXidx = 1d array of indices corresponding to regularized X covariates\nregZidx = 1d array of indices corresponding to regularized Z covariates\nreg = 2d array of bits, indicating whether or not to regularize each of the  coefficients\nnorms = 2d array of floats consisting of the norms corresponding to each  coefficient or nothing\n\nKeyword arguments\n\nisVerbose = boolean flag indicating whether or not to print messages.   Defaults to true. \nstepsize = float; step size for updates. Defaults to 0.01. \nthresh = threshold at which the coefficients are considered to have  converged, a floating scalar. Defaults to 10^(-7). \nmaxiter = maximum number of update iterations. Defaults to 10^10. \n\nValue\n\nNone; updates coefficients in place\n\nSome notes\n\nConvergence is determined as when the log ratio of the current and previous  criteria is less than the threshold thresh. \n\nThe default method for choosing the fixed step size for ista! is to use the  reciprocal of the product of the maximum eigenvalues of X*transpose(X)  and Z*transpose(Z). This is computed by the mlmnet function when ista!  is passed into the fun argument and setStepSize is set to true. If  setStepSize is set to false, the value of the stepsize argument will be  used as the fixed step size. Note that obtaining the eigenvalues when X  and/or Z are very large may exceed computational limitations. \n\n\n\n\n\n","category":"method"},{"location":"functions/#MatrixLMnet.lambda_min-Tuple{Mlmnet_cv}","page":"Types and Functions","title":"MatrixLMnet.lambda_min","text":"lambda_min(MLMNet_cv::Mlmnet_cv)\n\nReturns summary information for lambdas corresponding to the minimum average  test MSE across folds and the MSE one that is standard error greater. \n\nArguments\n\nMLMNetcv = MLMNetcv object\n\nValue\n\nDataFrame from mlmnetcvsummary restricted to the lambdas and alphas that correspond to  the minimum average test MSE across folds and the MSE that is one standard  error greater. \n\n\n\n\n\n","category":"method"},{"location":"functions/#MatrixLMnet.make_folds","page":"Types and Functions","title":"MatrixLMnet.make_folds","text":"make_folds(n::Int64, k::Int64=10, k2::Int64=k)\n\nGenerate k non-overlapping folds. \n\nArguments\n\nn = Total number of observations to split into folds. \nk = Number of folds to create. Defaults to 10. If k=1, then all the data  (along this dimension) will be included in each fold. \nk2 = If k=1, then all the data (along this dimension) will be included in  each fold. k2 specifies how many folds there are. Defaults to k, which  is kind of silly, but there needs to be a placeholder. \n\nValue\n\n1d array of length k of arrays of indices \n\n\n\n\n\n","category":"function"},{"location":"functions/#MatrixLMnet.make_folds_conds","page":"Types and Functions","title":"MatrixLMnet.make_folds_conds","text":"make_folds_conds(conds::AbstractArray{String,1}, \n                     k::Int64=10, prop::Float64=1/k)\n\nGenerate k folds for a set of conditions, making sure each level of each  condition is represented in each fold. \n\nArguments\n\nconds = 1d array of conditions (strings)\nk = Number of folds to create. Defaults to 10. \nprop = Proportion of each condition level's replicates to include in each  fold. Defaults to 1/k. Each fold will contain at least one replicate of  each condition level. \n\nValue\n\n1d array of length k of arrays of indices \n\n\n\n\n\n","category":"function"},{"location":"functions/#MatrixLMnet.mlmnet-Tuple{RawData, AbstractVector{Float64}, AbstractVector{Float64}}","page":"Types and Functions","title":"MatrixLMnet.mlmnet","text":"mlmnet(data::RawData, \n            lambdas::AbstractArray{Float64,1}, alphas::AbstractArray{Float64,1};\n            method::String = \"ista\", \n            isNaive::Bool=false,\n            addXIntercept::Bool=true, addZIntercept::Bool=true, \n            toXReg::BitArray{1}=trues(data.p), \n            toZReg::BitArray{1}=trues(data.q),     \n            toXInterceptReg::Bool=false, toZInterceptReg::Bool=false, \n            toNormalize::Bool=true, isVerbose::Bool=true, \n            stepsize::Float64=0.01, setStepsize::Bool=true, \n            funArgs...)\n\nCenters and normalizes X and Z predictor matrices, calculates fixed step size, performs  the supplied method on two descending lists of lambdas and alphas (each for L1 and L2) using ``warm starts'',  and backtransforms resulting coefficients, as is deemed necessary by the user  inputs.\n\nArguments\n\ndata = RawData object\nlambdas = 1d array of floats consisting of the total penalties in descending  order. If they are not in descending order, they will be sorted. \nalphas = 1d array of floats consisting of the penalty ratio that  determines the mix of penalties between L1 and L2\n\nKeyword arguments\n\nmethods = function name that applies the Elastic-net penalty estimate method; default is ista, and the other methods are fista, fista_bt, admm and cd\nisNaive = boolean flag indicating whether to solve the Naive or non-Naive  Elastic-net problem\naddXIntercept = boolean flag indicating whether or not to include an X  intercept (row main effects). Defaults to true. \naddZIntercept = boolean flag indicating whether or not to include a Z  intercept (column main effects). Defaults to true.\ntoXReg = 1d array of bit flags indicating whether or not to regularize each  of the X (row) effects. Defaults to 2d array of trues with length  equal to the number of X effects (equivalent to data.p). \ntoZReg = 1d array of bit flags indicating whether or not to regularize each  of the Z (column) effects. Defaults to 2d array of trues with length  equal to the number of Z effects (equivalent to data.q). \ntoXInterceptReg = boolean flag indicating whether or not to regularize the  X intercept Defaults to false. \ntoZInterceptReg = boolean flag indicating whether or not to regularize the  Z intercept. Defaults to false. \ntoNormalize = boolean flag indicating if the columns of X and Z  should be standardized (to mean 0, standard deviation 1). Defaults to true.\nisVerbose = boolean flag indicating whether or not to print messages.   Defaults to true. \nstepsize = float; step size for updates (irrelevant for coordinate  descent and when setStepsize is set to true for ista! and fista!).  Defaults to 0.01. \nsetStepsize = boolean flag indicating whether the fixed step size should be  calculated (for ista! and fista!). Defaults to true.\nfunArgs = variable keyword arguments to be passed into fun\n\nValue\n\nAn Mlmnet object\n\nSome notes\n\nThe default method for choosing the fixed step size for fista! or istaNet!  is to use the reciprocal of the product of the maximum eigenvalues of  X*transpose(X) and Z*transpose(Z). This is computed when fista! or  ista! is passed into the fun argument and setStepsize is set to true.  If setStepsize is set to false, the value of the stepsize argument will  be used as the fixed step size. Note that obtaining the eigenvalues when X  and/or Z are very large may exceed computational limitations. \n\nSpecifying a good starting step size (stepsize) and multiplying factor  (gamma) when fista_bt! is passed into the fun argument can be difficult.  Shrinking the step size too gradually can result in slow convergence. Doing so  too quickly can cause the criterion to diverge. We have found that setting  stepsize to 0.01 often works well in practice; choice of gamma appears to  be less consequential. \n\n\n\n\n\n","category":"method"},{"location":"functions/#MatrixLMnet.mlmnet_bic-Tuple{RawData, AbstractVector{Float64}, AbstractVector{Float64}}","page":"Types and Functions","title":"MatrixLMnet.mlmnet_bic","text":"mlmnet_bic(data::RawData, \n               lambdas::AbstractArray{Float64,1},\n               alphas::AbstractArray{Float64,1}; \n               method::String=\"ista\", isNaive::Bool=false,\n               addXIntercept::Bool=true, addZIntercept::Bool=true, \n               toXReg::BitArray{1}=trues(size(get_X(data), 2)), \n               toZReg::BitArray{1}=trues(size(get_Z(data), 2)), \n               toXInterceptReg::Bool=false, toZInterceptReg::Bool=false, \n               toNormalize::Bool=true, isVerbose::Bool=true, \n               stepsize::Float64=0.01, setStepsize::Bool=true, \n               dig::Int64=12, funArgs...)\n\nPerforms BIC validation for mlmnet. \n\nArguments\n\ndata = RawData object\nlambdas = 1d array of floats consisting of the total penalties in descending  order. If they are not in descending order, they will be sorted. \nalphas = 1d array of floats consisting of the penalty ratio that  determines the mix of penalties between L1 and L2\n\nKeyword arguments\n\nmethods = function name that applies the Elastic-net penalty estimate method; default is ista, and the other methods are fista, fista_bt, admm and cd\nisNaive = boolean flag indicating whether to solve the Naive or non-Naive  Elastic-net problem\naddXIntercept = boolean flag indicating whether or not to include an X  intercept (row main effects). Defaults to true. \naddZIntercept = boolean flag indicating whether or not to include a Z  intercept (column main effects). Defaults to true.\ntoXReg = 1d array of bit flags indicating whether or not to regularize each  of the X (row) effects. Defaults to 2d array of trues with length  equal to the number of X effects (equivalent to data.p). \ntoZReg = 1d array of bit flags indicating whether or not to regularize each  of the Z (column) effects. Defaults to 2d array of trues with length  equal to the number of Z effects (equivalent to data.q). \ntoXInterceptReg = boolean flag indicating whether or not to regularize the  X intercept Defaults to false. \ntoZInterceptReg = boolean flag indicating whether or not to regularize the  Z intercept. Defaults to false. \ntoNormalize = boolean flag indicating if the columns of X and Z  should be standardized (to mean 0, standard deviation 1). Defaults to true.\nisVerbose = boolean flag indicating whether or not to print messages.   Defaults to true. \nstepsize = float; step size for updates (irrelevant for coordinate  descent and when setStepsize is set to true for ista! and fista!).  Defaults to 0.01. \nsetStepsize = boolean flag indicating whether the fixed step size should be  calculated (for ista! and fista!). Defaults to true.\ndig = integer; digits of precision for zero coefficients. Defaults to 12. \nfunArgs = variable keyword arguments to be passed into fun\n\nValue\n\nAn Mlmnet_bic object. \n\nSome notes\n\nThis is the base mlmnet_bic function that all other variants call. \n\n\n\n\n\n","category":"method"},{"location":"functions/#MatrixLMnet.mlmnet_bic_summary-Tuple{Mlmnet_bic}","page":"Types and Functions","title":"MatrixLMnet.mlmnet_bic_summary","text":"mlmnet_bic_summary(MLMNet_bic::Mlmnet_bic)\n\nSummarizes results of BIC-validation by returning a table with: \n\nLambdas used\nMSE across folds for each lambda\nProportion of zero interaction coefficients across each pair  of lambda and alpha\n\nArguments\n\nMLMNetbic = Mlmnetbic object\n\nValue\n\nDataFrame summarizing BIC, MSE, proportion of zero interactions across each pair  of lambda and alpha. \n\n\n\n\n\n","category":"method"},{"location":"functions/#MatrixLMnet.mlmnet_cv-Tuple{RawData, AbstractVector{Float64}, AbstractVector{Float64}, Vector{Vector{Int64}}, Vector{Vector{Int64}}}","page":"Types and Functions","title":"MatrixLMnet.mlmnet_cv","text":"mlmnet_cvmlmnet_cv(data::RawData, \n               lambdas::AbstractArray{Float64,1},\n               alphas::AbstractArray{Float64,1}, \n               rowFolds::Array{Array{Int64,1},1}, \n               colFolds::Array{Array{Int64,1},1}; \n               method::String=\"ista\", isNaive::Bool=false,\n               addXIntercept::Bool=true, addZIntercept::Bool=true, \n               toXReg::BitArray{1}=trues(size(get_X(data), 2)), \n               toZReg::BitArray{1}=trues(size(get_Z(data), 2)), \n               toXInterceptReg::Bool=false, toZInterceptReg::Bool=false, \n               toNormalize::Bool=true, isVerbose::Bool=true, \n               stepsize::Float64=0.01, setStepsize::Bool=true, \n               dig::Int64=12, funArgs...)\n\nPerforms cross-validation for mlmnet using row and column folds from user  input. \n\nArguments\n\ndata = RawData object\nlambdas = 1d array of floats consisting of the total penalties in descending  order. If they are not in descending order, they will be sorted. \nalphas = 1d array of floats consisting of the penalty ratio that  determines the mix of penalties between L1 and L2\nrowFolds = 1d array of arrays (one array for each fold), each containing  the indices for a row fold; must be same length as colFolds. Can be  generated with a call to make_folds, which is based on Kfold from the  MLBase package. \ncolFolds = 1d array of arrays (one array for each fold), each containing  the indices for a column fold; must be same length as rowFolds. Can be  generated with a call to make_folds, which is based on Kfold from the  MLBase package\n\nKeyword arguments\n\nmethods = function name that applies the Elastic-net penalty estimate method; default is ista, and the other methods are fista, fista_bt, admm and cd\nisNaive = boolean flag indicating whether to solve the Naive or non-Naive  Elastic-net problem\naddXIntercept = boolean flag indicating whether or not to include an X  intercept (row main effects). Defaults to true. \naddZIntercept = boolean flag indicating whether or not to include a Z  intercept (column main effects). Defaults to true.\ntoXReg = 1d array of bit flags indicating whether or not to regularize each  of the X (row) effects. Defaults to 2d array of trues with length  equal to the number of X effects (equivalent to data.p). \ntoZReg = 1d array of bit flags indicating whether or not to regularize each  of the Z (column) effects. Defaults to 2d array of trues with length  equal to the number of Z effects (equivalent to data.q). \ntoXInterceptReg = boolean flag indicating whether or not to regularize the  X intercept Defaults to false. \ntoZInterceptReg = boolean flag indicating whether or not to regularize the  Z intercept. Defaults to false. \ntoNormalize = boolean flag indicating if the columns of X and Z  should be standardized (to mean 0, standard deviation 1). Defaults to true.\nisVerbose = boolean flag indicating whether or not to print messages.   Defaults to true. \nstepsize = float; step size for updates (irrelevant for coordinate  descent and when setStepsize is set to true for ista! and fista!).  Defaults to 0.01. \nsetStepsize = boolean flag indicating whether the fixed step size should be  calculated (for ista! and fista!). Defaults to true.\ndig = integer; digits of precision for zero coefficients. Defaults to 12. \nfunArgs = variable keyword arguments to be passed into fun\n\nValue\n\nAn Mlmnet_cv object. \n\nSome notes\n\nThis is the base mlmnet_cv function that all other variants call. Folds  are computed in parallel when possible. \n\n\n\n\n\n","category":"method"},{"location":"functions/#MatrixLMnet.mlmnet_cv_summary-Tuple{Mlmnet_cv}","page":"Types and Functions","title":"MatrixLMnet.mlmnet_cv_summary","text":"mlmnet_cv_summary(MLMNet_cv::Mlmnet_cv)\n\nSummarizes results of cross-validation by returning a table with: \n\nLambdas used\nAverage MSE across folds for each lambda\nAverage proportion of zero interaction coefficeints across folds for each  lambda\n\nArguments\n\nMLMNetcv = MLMNetcv object\n\nValue\n\nDataFrame summarizing average MSE and proportion of zero interactions across  folds for each lambda. \n\n\n\n\n\n","category":"method"},{"location":"functions/#MatrixLMnet.mlmnet_pathwise-Tuple{Function, AbstractMatrix{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}, AbstractVector{Float64}, AbstractVector{Float64}, AbstractVector{Int64}, AbstractVector{Int64}, BitMatrix, Any}","page":"Types and Functions","title":"MatrixLMnet.mlmnet_pathwise","text":"mlmnet_pathwise(fun::Function, X::AbstractArray{Float64,2}, \n                     Y::AbstractArray{Float64,2}, \n                     Z::AbstractArray{Float64,2}, \n                     lambdas::AbstractArray{Float64,1},\n                     alphas::AbstractArray{Float64, 1},  \n                     regXidx::AbstractArray{Int64,1}, \n                     regZidx::AbstractArray{Int64,1}, \n                     reg::BitArray{2}, norms; isVerbose::Bool=true, \n                     stepsize::Float64=0.01, funArgs...)\n\nPerforms the supplied method on two descending lists of lambdas (for l1 and l2)  using ``warm starts''. \n\nArguments\n\nfun = function that applies the Elastic-net pentalty estimate method\nX = 2d array of floats consisting of the row covariates, with all  categorical variables coded in appropriate contrasts\nY = 2d array of floats consisting of the multivariate response\nZ = 2d array of floats consisting of the column covariates, with all  categorical variables coded in appropriate contrasts\nlambdas = 1d array of floats consisting of the total penalties in descending  order. If they are not in descending order, they will be sorted.\nalphas = 1d array of floats consisting of the penalty ratio that  determines the mix of penalties between L1 and L2\nregXidx = 1d array of indices corresponding to regularized X covariates\nregZidx = 1d array of indices corresponding to regularized Z covariates\nreg = 2d array of bits, indicating whether or not to regularize each of the  coefficients\nnorms = 2d array of floats consisting of the norms corresponding to each  coefficient or nothing\n\nKeyword arguments\n\nisVerbose = boolean flag indicating whether or not to print messages.   Defaults to true. \nstepsize = float; step size for updates. Defaults to 0.01. \nfunArgs = variable keyword arguments to be passed into fun\n\nValue\n\nA 4d array consisting of the coefficient estimates, with the different  lambdas and alphas along the first and second dimensions respectively\n\nSome notes\n\nAssumes that all necessary standardizations have been performed on X, Y, and  Z, including adding on intercepts. To be called by mlmnet, which performs  standardization and backtransforming. \n\n\n\n\n\n","category":"method"},{"location":"functions/#MatrixLMnet.mlmnet_perms-Tuple{RawData, AbstractVector{Float64}, AbstractVector{Float64}}","page":"Types and Functions","title":"MatrixLMnet.mlmnet_perms","text":"mlmnet_perms(data::RawData, \n                  lambdas::AbstractArray{Float64,1}, alphas::AbstractArray{Float64,1};\n                  method::String = \"ista\", isNaive::Bool=false, \n                  permFun::Function=shuffle_rows, \n                  addXIntercept::Bool=true, addZIntercept::Bool=true, \n                  toXReg::BitArray{1}=trues(data.p), \n                  toZReg::BitArray{1}=trues(data.q), \n                  toXInterceptReg::Bool=false, \n                  toZInterceptReg::Bool=false, \n                  toNormalize::Bool=true, isVerbose::Bool=true, \n                  stepsize::Float64=0.01, setStepsize=true, funArgs...)\n\nPermutes response matrix Y in RawData object and then calls the mlmnet core  function. \n\nArguments\n\ndata = RawData object\nlambdas = 1d array of floats consisting of the total penalties in descending  order. If they are not in descending order, they will be sorted. \nalphas = 1d array of floats consisting of the penalty ratio that  determines the mix of penalties between L1 and L2 \n\nKeyword arguments\n\nmethods = function name that applies the Elastic-net penalty estimate method; default is ista, and the other methods are fista, fista_bt, admm and cd\nisNaive = boolean flag indicating whether to solve the Naive or non-Naive  Elastic-net problem\npermFun = function used to permute Y. Defaults to shuffle_rows  (shuffles rows of Y). \naddXIntercept = boolean flag indicating whether or not to include an X  intercept (row main effects). Defaults to true. \naddZIntercept = boolean flag indicating whether or not to include a Z  intercept (column main effects). Defaults to true.\ntoXReg = 1d array of bit flags indicating whether or not to regularize each  of the X (row) effects. Defaults to 2d array of trues with length  equal to the number of X effects (equivalent to data.p). \ntoZReg = 1d array of bit flags indicating whether or not to regularize each  of the Z (column) effects. Defaults to 2d array of trues with length  equal to the number of Z effects (equivalent to data.q). \ntoXInterceptReg = boolean flag indicating whether or not to regularize the  X intercept Defaults to false. \ntoZInterceptReg = boolean flag indicating whether or not to regularize the  Z intercept. Defaults to false. \ntoNormalize = boolean flag indicating if the columns of X and Z  should be standardized (to mean 0, standard deviation 1). Defaults to true.\nisVerbose = boolean flag indicating whether or not to print messages.   Defaults to true. \nsetStepsize = boolean flag indicating whether the fixed step size should be  calculated (for ista! and fista!). Defaults to true.\nstepsize = float; step size for updates (irrelevant for coordinate  descent and when setStepsize is set to true for ista! and fista!).  Defaults to 0.01. \nfunArgs = variable keyword arguments to be passed into fun\n\nValue\n\nAn MLMnet object\n\nSome notes\n\nThe default method for choosing the fixed step size for fista! or ista!  is to use the reciprocal of the product of the maximum eigenvalues of  X*transpose(X) and Z*transpose(Z). This is computed when fista! or  ista! is passed into the fun argument and setStepsize is set to true.  If setStepsize is set to false, the value of the stepsize argument will  be used as the fixed step size. Note that obtaining the eigenvalues when X  and/or Z are very large may exceed computational limitations. \n\nSpecifying a good starting step size (stepsize) and multiplying factor  (gamma) when fista_bt! is passed into the fun argument can be difficult.  Shrinking the step size too gradually can result in slow convergence. Doing so  too quickly can cause the criterion to diverge. We have found that setting  stepsize to 0.01 often works well in practice; choice of gamma appears to  be less consequential. \n\n\n\n\n\n","category":"method"},{"location":"functions/#MatrixLMnet.normalize!-Tuple{AbstractMatrix{Float64}, Bool}","page":"Types and Functions","title":"MatrixLMnet.normalize!","text":"normalize!(A::AbstractArray{Float64,2}, hasIntercept::Bool)\n\nCenters and normalizes the columns of A in place\n\nArguments\n\nA = 2d array of floats\nhasIntercept = boolean flag indicating whether the first column of A is the  intercept\n\nValue\n\nCenters and normalizes A in place and returns 2d arrays of the column means and L2  norms of A before standardization. \n\n\n\n\n\n","category":"method"},{"location":"functions/#MatrixLMnet.outer_update_fista_bt!-Tuple{AbstractMatrix{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}, Any, Float64, Float64, BitMatrix, AbstractVector{Int64}, AbstractVector{Float64}, Float64}","page":"Types and Functions","title":"MatrixLMnet.outer_update_fista_bt!","text":"outer_update_fista_bt!(B::AbstractArray{Float64,2}, \n                            B_prev::AbstractArray{Float64,2}, \n                            A::AbstractArray{Float64,2}, \n                            resid::AbstractArray{Float64,2}, \n                            resid_B::AbstractArray{Float64,2}, \n                            grad::AbstractArray{Float64,2}, \n                            X::AbstractArray{Float64,2}, \n                            Y::AbstractArray{Float64,2}, \n                            Z::AbstractArray{Float64,2}, \n                            norms, lambdaL1::Float64, lambdaL2::Float64,\n                            reg::BitArray{2}, \n                            iter::AbstractArray{Int64,1}, \n                            stepsize::AbstractArray{Float64,1}, \n                            gamma::Float64)\n\nUses backtracking to update step size for FISTA. \n\nArguments\n\nB = 2d array of floats consisting of coefficient estimates\nB_prev = 2d array of floats consisting of coefficient estimates saved from  the previous iteration\nA = 2d array of floats consisting of extrapolated coefficients \nresid = 2d array of floats consisting of the residuals calculated from the  extrapolated coefficients\nresid_B = 2d array of floats consisting of the residuals calculated from  the coefficient estimates\ngrad = 2d array of floats consisting of the gradient\nX = 2d array of floats consisting of the row covariates, with all  categorical variables coded in appropriate contrasts\nY = 2d array of floats consisting of the multivariate response observations\nZ = 2d array of floats consisting of the column covariates, with all  categorical variables coded in appropriate contrasts\nnorms = 2d array of floats consisting of the norms corresponding to each  coefficient or nothing\nlambdaL1 = l1 penalty, a floating scalar\nlambdaL2 = l2 penalty, a floating scalar\nreg = 2d array of bits, indicating whether or not to regularize each of the  coefficients\niter = 1d array consisting of a single integer keeping track of how many  iterations have been computed\nstepsize = 1d array consisting of a float; step size of updates\ngamma = float; multiplying factor for step size backtracking/line search\n\nValue\n\nNone; updates coefficients and step size in place\n\n\n\n\n\n","category":"method"},{"location":"functions/#MatrixLMnet.predict","page":"Types and Functions","title":"MatrixLMnet.predict","text":"predict(MLMNet::Mlmnet, newPredictors::Predictors=MLMNet.data.predictors)\n\nCalculate new predictions based on Mlmnet object\n\nArguments\n\nMLMNet = Mlmnet object\nnewPredictors = Predictors object. Defaults to the data.predictors field  in the MLM object used to fit the model. \n\nValue\n\n4d array of predicted values\n\n\n\n\n\n","category":"function"},{"location":"functions/#MatrixLMnet.predict-2","page":"Types and Functions","title":"MatrixLMnet.predict","text":"predict(MLMNet::Mlmnet, lambda::Float64, alpha::Float64,\n             newPredictors::Predictors=MLMNet.data.predictors)\n\nCalculate new predictions based on Mlmnet object and given a lambda \n\nArguments\n\nMLMNet = Mlmnet object\nlambda = lambda penalty to use, a floating scalar\nalpha = alpha penalty to determine the mix of penalties between L1 and L2 a floating scalar\nnewPredictors = Predictors object. Defaults to the data.predictors field  in the MLM object used to fit the model. \n\nValue\n\n2d array of predicted values\n\n\n\n\n\n","category":"function"},{"location":"functions/#MatrixLMnet.println_verbose","page":"Types and Functions","title":"MatrixLMnet.println_verbose","text":"println_verbose(x, isVerbose::Bool=true)\n\nVersion of println that only prints when isVerbose flag is true\n\nArguments\n\nx = something that can be printed\nisVerbose = boolean flag indicating whether or not to print messages.  Defaults to true. \n\nValue\n\nNone; prints to console\n\n\n\n\n\n","category":"function"},{"location":"functions/#MatrixLMnet.prox-NTuple{5, Float64}","page":"Types and Functions","title":"MatrixLMnet.prox","text":"prox(b::Float64, gradient::Float64, b2sign::Float64, \n          lambda::Float64, norm::Float64)\n\nProximal (soft-thresholding) operator when step size is 1\n\nArguments\n\nb = coefficient to update, a float\ngradient = gradient of b, a float\nb2sign = sign of b + stepsize*gradient, a float\nlambda = lambda penalty , a float\nnorm = norm corresponding to b, a float\n\nValue\n\nA floating scalar\n\n\n\n\n\n","category":"method"},{"location":"functions/#MatrixLMnet.prox-NTuple{6, Float64}","page":"Types and Functions","title":"MatrixLMnet.prox","text":"prox(b, gradient, b2sign, lambda, norm, stepsize)\n\nProximal (soft-thresholding) operator\n\nArguments\n\nb = coefficient to update, a float\ngradient = gradient of b, a float\nb2sign = sign of b + stepsize*gradient, a float\nlambda = lambda penalty , a float\nnorm = norm corresponding to b, a float\nstepsize = step size to multiply updates, a float\n\nValue\n\nA floating scalar\n\n\n\n\n\n","category":"method"},{"location":"functions/#MatrixLMnet.prox-Tuple{Float64, Float64, Float64, Float64, Nothing, Float64}","page":"Types and Functions","title":"MatrixLMnet.prox","text":"prox(b::Float64, gradient::Float64, b2sign::Float64, \n          lambda::Float64, norm::Nothing, stepsize::Float64)\n\nProximal (soft-thresholding) operator when not incorporating the norms  (norms=1)\n\nArguments\n\nb = coefficient to update, a float\ngradient = gradient of b, a float\nb2sign = sign of b + stepsize*gradient, a float\nlambda = lambda penalty , a float\nnorm = Nothing\nstepsize = step size to multiply updates, a float\n\nValue\n\nA floating scalar\n\n\n\n\n\n","category":"method"},{"location":"functions/#MatrixLMnet.prox-Tuple{Float64, Float64, Float64, Float64, Nothing}","page":"Types and Functions","title":"MatrixLMnet.prox","text":"prox(b, gradient, b2sign, lambda, norm)\n\nProximal (soft-thresholding) operator when not incorporating the norms  (norms=1) and step size is 1\n\nArguments\n\nb = coefficient to update, a float\ngradient = gradient of b, a float\nb2sign = sign of b + stepsize*gradient, a float\nlambda = lambda penalty , a float\nnorm = Nothing\n\nValue\n\nA floating scalar\n\n\n\n\n\n","category":"method"},{"location":"functions/#MatrixLMnet.prox_mat-Tuple{AbstractMatrix{Float64}, AbstractMatrix{Float64}, Float64, AbstractMatrix{Float64}, Float64}","page":"Types and Functions","title":"MatrixLMnet.prox_mat","text":"prox_mat(b::AbstractArray{Float64,2}, b2sign::AbstractArray{Float64,2}, \n              lambda::Float64, norm::AbstractArray{Float64,2}, stepsize::Float64)\n\nProximal (soft-thresholding) operator\n\nArguments\n\nb = coefficient to update, a float\nb2sign = sign of b + stepsize*gradient, a float\nlambda = lambda penalty , a float\nnorm = norm corresponding to b, a float\nstepsize = step size to multiply updates, a float\n\nValue\n\nA floating scalar\n\n\n\n\n\n","category":"method"},{"location":"functions/#MatrixLMnet.prox_mat-Tuple{AbstractMatrix{Float64}, AbstractMatrix{Float64}, Float64, AbstractMatrix{Float64}}","page":"Types and Functions","title":"MatrixLMnet.prox_mat","text":"prox_mat(b::AbstractArray{Float64,2}, b2sign::AbstractArray{Float64,2}, \n              lambda::Float64, norm::AbstractArray{Float64,2})\n\nProximal (soft-thresholding) operator\n\nArguments\n\nb = coefficient to update, a float\nb2sign = sign of b + stepsize*gradient, a float\nlambda = lambda penalty , a float\nnorm = norm corresponding to b, a float\n\nValue\n\nA floating scalar\n\n\n\n\n\n","category":"method"},{"location":"functions/#MatrixLMnet.prox_mat-Tuple{AbstractMatrix{Float64}, AbstractMatrix{Float64}, Float64, Nothing, Float64}","page":"Types and Functions","title":"MatrixLMnet.prox_mat","text":"prox_mat(b::Float64, gradient::Float64, b2sign::Float64, \n          lambda::Float64, norm::Nothing, stepsize::Float64)\n\nProximal (soft-thresholding) operator when not incorporating the norms  (norms=1)\n\nArguments\n\nb = coefficient to update, a float\ngradient = gradient of b, a float\nb2sign = sign of b + stepsize*gradient, a float\nlambda = lambda penalty , a float\nnorm = Nothing\nstepsize = step size to multiply updates, a float\n\nValue\n\nA floating scalar\n\n\n\n\n\n","category":"method"},{"location":"functions/#MatrixLMnet.resid","page":"Types and Functions","title":"MatrixLMnet.resid","text":"resid(MLMNet::Mlmnet, newData::RawData=MLMNet.data)\n\nCalculate residuals of an MLMNet object\n\nArguments\n\nMLMNet = Mlmnet object\nnewData = RawData object. Defaults to the data field in the MLM object  used to fit the model. \n\nValue\n\n3d array of residuals\n\n\n\n\n\n","category":"function"},{"location":"functions/#MatrixLMnet.resid-2","page":"Types and Functions","title":"MatrixLMnet.resid","text":"resid(MLMNet::Mlmnet, lambda::Float64, alpha::Float64, newData::RawData=MLMNet.data)\n\nCalculate residuals of an MLMNet object, given a lambda \n\nArguments\n\nMLMNet = Mlmnet object\nlambda = lambda penalty to use, a floating scalar\nalpha = alpha penalty to determine the mix of penalties between L1 and L2 a floating scalar\nnewData = RawData object. Defaults to the data field in the MLM object  used to fit the model. \n\nValue\n\n2d array of residuals\n\n\n\n\n\n","category":"function"},{"location":"functions/#MatrixLMnet.update_admm!-Tuple{AbstractMatrix{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}, Float64, Float64, AbstractVector{Int64}, AbstractVector{Int64}, AbstractVector{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}, Float64, Float64, Float64}","page":"Types and Functions","title":"MatrixLMnet.update_admm!","text":"update_admm!update_admm!(B::AbstractArray{Float64,2}, \n                  B0::AbstractArray{Float64,2}, \n                  B2::AbstractArray{Float64,2}, \n                  resid::AbstractArray{Float64,2}, \n                  X::AbstractArray{Float64,2}, \n                  Y::AbstractArray{Float64,2}, \n                  Z::AbstractArray{Float64,2}, \n                  Qx::AbstractArray{Float64,2}, \n                  Qz::AbstractArray{Float64,2}, \n                  U::AbstractArray{Float64,2}, \n                  L::AbstractArray{Float64,2}, \n                  lambdaL1::Float64, lambdaL2::Float64, \n                  regXidx::AbstractArray{Int64,1}, \n                  regZidx::AbstractArray{Int64,1}, \n                  rho::AbstractArray{Float64,1}, \n                  r::AbstractArray{Float64,2}, \n                  s::AbstractArray{Float64,2}, \n                  tau_incr::Float64, tau_decr::Float64, mu::Float64)\n\nUpdates coefficient estimates in place for each ADMM iteration. \n\nArguments\n\nB = 2d array of floats consisting of coefficient estimates for L1 updates\nB0 = 2d array of floats consisting of coefficient estimates for L2 updates\nB2 = 2d array of floats consisting of coefficient estimates for dual updates\nresid = 2d array of floats consisting of the residuals\nX = 2d array of floats consisting of the row covariates, with all  categorical variables coded in appropriate contrasts\nY = 2d array of floats consisting of the multivariate response\nZ = 2d array of floats consisting of the column covariates, with all  categorical variables coded in appropriate contrasts\nQx = 2d array of floats consisting of the eigenvectors of X\nQz = 2d array of floats consisting of the eigenvectors of Z\nU = 2d array of floats consisting of the transformed Y matrix\nL = 2d array of floats consisting of the kronecker product of the  eigenvalues of X and Z\nlambdaL1 = l1 penalty, a floating scalar\nlambdaL2 = l2 penalty, a floating scalar\nregXidx = 1d array of indices corresponding to regularized X covariates\nregZidx = 1d array of indices corresponding to regularized Z covariates\nrho = float; parameter that controls ADMM tuning. \nr = 2d array of floats consisting of the primal residuals. \ns = 2d array of floats consisting of the dual residuals. \ntau_incr = float; parameter that controls the factor at which rho increases.  Defaults to 2.0. \ntau_decr = float; parameter that controls the factor at which rho decreases.  Defaults to 2.0. \nmu = float; parameter that controls the factor at which the primal and dual  residuals should be within each other. Defaults to 10.0. \n\nValue\n\nNone; updates coefficients in place\n\nSome notes\n\nConvergence is determined as when the log ratio of the current and previous  criteria is less than the threshold thresh. \n\nrho controls ADMM tuning and can be specified by the user. \n\n\n\n\n\n","category":"method"},{"location":"functions/#MatrixLMnet.update_cd_active_cyclic!-Tuple{AbstractMatrix{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}, Any, Float64, BitMatrix, Tuple{AbstractVector{Int64}, AbstractVector{Int64}}, Tuple{AbstractVector{Int64}, AbstractVector{Int64}}}","page":"Types and Functions","title":"MatrixLMnet.update_cd_active_cyclic!","text":"update_cd_active_cyclic!(B::AbstractArray{Float64,2}, \n                              resid::AbstractArray{Float64,2},\n                              X::AbstractArray{Float64,2}, \n                              Z::AbstractArray{Float64,2}, \n                              norms, lambda::Float64, reg::BitArray{2}, \n                              nonreg_idx::Tuple{AbstractArray{Int64,1},\n                                                AbstractArray{Int64,1}}, \n                              active_idx::Tuple{AbstractArray{Int64,1},\n                                                AbstractArray{Int64,1}})\n\nCyclically updates active set of coefficients in place for each coordinate  descent iteration.\n\nArguments\n\nB = 2d array of floats consisting of coefficient estimates\nresid = 2d array of floats consisting of the residuals\nX = 2d array of floats consisting of the row covariates, with all  categorical variables coded in appropriate contrasts\nZ = 2d array of floats consisting of the column covariates, with all  categorical variables coded in appropriate contrasts\nnorms = 2d array of floats consisting of the norms corresponding to each  coefficient or nothing\nlambda = lambda penalty, a floating scalar\nreg = 2d array of bits, indicating whether or not to regularize each of the  coefficients\nnonreg_idx = tuple with the 2d indices of the non-regularized coefficients  as two 1d arrays of integers\nactive_idx = tuple with the 2d indices of the active coefficients as two 1d  arrays of integers\n\nValue\n\nNone; updates coefficients in place\n\nSome notes\n\nGiven that you pass in the indices for the non-regularized and active  (regularized) coefficients separately, this function can be further optimized  so that you don't check for regularization when updating each coefficient  with inner_update!.\n\n\n\n\n\n","category":"method"},{"location":"functions/#MatrixLMnet.update_cd_active_random!-Tuple{AbstractMatrix{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}, Any, Float64, BitMatrix, Tuple{AbstractVector{Int64}, AbstractVector{Int64}}, Tuple{AbstractVector{Int64}, AbstractVector{Int64}}}","page":"Types and Functions","title":"MatrixLMnet.update_cd_active_random!","text":"update_cd_active_random!(B::AbstractArray{Float64,2}, \n                              resid::AbstractArray{Float64,2},\n                              X::AbstractArray{Float64,2}, \n                              Z::AbstractArray{Float64,2}, \n                              norms, lambda::Float64, reg::BitArray{2}, \n                              nonreg_idx::Tuple{AbstractArray{Int64,1},\n                                                AbstractArray{Int64,1}}, \n                              active_idx::Tuple{AbstractArray{Int64,1},\n                                                AbstractArray{Int64,1}})\n\nRandomly updates active set of coefficients in place for each coordinate  descent iteration.\n\nArguments\n\nB = 2d array of floats consisting of coefficient estimates\nresid = 2d array of floats consisting of the residuals\nX = 2d array of floats consisting of the row covariates, with all  categorical variables coded in appropriate contrasts\nZ = 2d array of floats consisting of the column covariates, with all  categorical variables coded in appropriate contrasts\nnorms = 2d array of floats consisting of the norms corresponding to each  coefficient or nothing\nlambda = lambda penalty, a floating scalar\nreg = 2d array of bits, indicating whether or not to regularize each of the  coefficients\nnonreg_idx = tuple with the 2d indices of the non-regularized coefficients  as two 1d arrays of integers\nactive_idx = tuple with the 2d indices of the active coefficients as two 1d  arrays of integers\n\nValue\n\nNone; updates coefficients in place\n\n\n\n\n\n","category":"method"},{"location":"functions/#MatrixLMnet.update_cd_cyclic!-Tuple{AbstractMatrix{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}, Any, Float64, BitMatrix}","page":"Types and Functions","title":"MatrixLMnet.update_cd_cyclic!","text":"update_cd_cyclic!(B::AbstractArray{Float64,2}, \n                       resid::AbstractArray{Float64,2}, \n                       X::AbstractArray{Float64,2}, \n                       Z::AbstractArray{Float64,2}, \n                       norms, lambda::Float64, reg::BitArray{2})\n\nCyclically updates coefficients in place for each coordinate descent iteration.\n\nArguments\n\nB = 2d array of floats consisting of coefficient estimates\nresid = 2d array of floats consisting of the residuals\nX = 2d array of floats consisting of the row covariates, with all  categorical variables coded in appropriate contrasts\nZ = 2d array of floats consisting of the column covariates, with all  categorical variables coded in appropriate contrasts\nnorms = 2d array of floats consisting of the norms corresponding to each  coefficient or nothing\nlambda = lambda penalty, a floating scalar\nreg = 2d array of bits, indicating whether or not to regularize each of the  coefficients\n\nValue\n\nNone; updates coefficients in place\n\n\n\n\n\n","category":"method"},{"location":"functions/#MatrixLMnet.update_cd_random!-Tuple{AbstractMatrix{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}, Any, Float64, BitMatrix}","page":"Types and Functions","title":"MatrixLMnet.update_cd_random!","text":"update_cd_random!(B::AbstractArray{Float64,2}, \n                       resid::AbstractArray{Float64,2}, \n                       X::AbstractArray{Float64,2}, \n                       Z::AbstractArray{Float64,2}, \n                       norms, lambda::Float64, reg::BitArray{2})\n\nRandomly updates coefficients in place for each coordinate descent iteration.\n\nArguments\n\nB = 2d array of floats consisting of coefficient estimates\nresid = 2d array of floats consisting of the residuals\nX = 2d array of floats consisting of the row covariates, with all  categorical variables coded in appropriate contrasts\nZ = 2d array of floats consisting of the column covariates, with all  categorical variables coded in appropriate contrasts\nnorms = 2d array of floats consisting of the norms corresponding to each  coefficient or nothing\nlambda = lambda penalty, a floating scalar\nreg = 2d array of bits, indicating whether or not to regularize each of the  coefficients\n\nValue\n\nNone; updates coefficients in place\n\n\n\n\n\n","category":"method"},{"location":"functions/#MatrixLMnet.update_fista!-Tuple{AbstractMatrix{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}, Float64, Float64, BitMatrix, AbstractVector{Int64}, AbstractVector{Float64}}","page":"Types and Functions","title":"MatrixLMnet.update_fista!","text":"update_fista!(B::AbstractArray{Float64,2}, \n                   B_prev::AbstractArray{Float64,2}, \n                   A::AbstractArray{Float64,2}, \n                   resid::AbstractArray{Float64,2}, \n                   resid_B::AbstractArray{Float64,2}, \n                   grad::AbstractArray{Float64,2}, \n                   X::AbstractArray{Float64,2}, \n                   Y::AbstractArray{Float64,2}, \n                   Z::AbstractArray{Float64,2}, \n                   norms::AbstractArray{Float64,2}, \n                   lambdaL1::Float64, lambdaL2::Float64, \n                   reg::BitArray{2}, \n                   iter::AbstractArray{Int64,1}, \n                   stepsize::AbstractArray{Float64,1})\n\nUpdates coefficient estimates in place for each FISTA iteration when X and  Z are not standardized. \n\nArguments\n\nB = 2d array of floats consisting of coefficient estimates\nB_prev = 2d array of floats consisting of coefficient estimates saved from  the previous iteration\nA = 2d array of floats consisting of extrapolated coefficients \nresid = 2d array of floats consisting of the residuals calculated from the  extrapolated coefficients\nresid_B = 2d array of floats consisting of the residuals calculated from  the coefficient estimates\ngrad = 2d array of floats consisting of the gradient\nX = 2d array of floats consisting of the row covariates, with all  categorical variables coded in appropriate contrasts\nY = 2d array of floats consisting of the multivariate response observations\nZ = 2d array of floats consisting of the column covariates, with all  categorical variables coded in appropriate contrasts\nnorms = 2d array of floats consisting of the norms corresponding to each  coefficient\nlambdaL1 = l1 penalty, a floating scalar\nlambdaL2 = l2 penalty, a floating scalar\nreg = 2d array of bits, indicating whether or not to regularize each of the  coefficients\niter = 1d array consisting of a single integer keeping track of how many  iterations have been computed\nstepsize = 1d array consisting of a float; step size of updates\n\nValue\n\nNone; updates coefficients in place\n\n\n\n\n\n","category":"method"},{"location":"functions/#MatrixLMnet.update_fista!-Tuple{AbstractMatrix{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}, Nothing, Float64, Float64, BitMatrix, AbstractVector{Int64}, AbstractVector{Float64}}","page":"Types and Functions","title":"MatrixLMnet.update_fista!","text":"update_fista!(B::AbstractArray{Float64,2}, \n                   B_prev::AbstractArray{Float64,2}, \n                   A::AbstractArray{Float64,2}, \n                   resid::AbstractArray{Float64,2}, \n                   resid_B::AbstractArray{Float64,2}, \n                   grad::AbstractArray{Float64,2}, \n                   X::AbstractArray{Float64,2}, \n                   Y::AbstractArray{Float64,2}, \n                   Z::AbstractArray{Float64,2}, \n                   norms::Nothing, lambdaL1::Float64, lambdaL2::Float64,\n                   reg::BitArray{2}, \n                   iter::AbstractArray{Int64,1}, \n                   stepsize::AbstractArray{Float64,1})\n\nUpdates coefficient estimates in place for each FISTA iteration based on the Elastic-net silution, when X and Z are both standardized. \n\nArguments\n\nB = 2d array of floats consisting of coefficient estimates\nB_prev = 2d array of floats consisting of coefficient estimates saved from  the previous iteration\nA = 2d array of floats consisting of extrapolated coefficients \nresid = 2d array of floats consisting of the residuals calculated from the  extrapolated coefficients\nresid_B = 2d array of floats consisting of the residuals calculated from  the coefficient estimates\ngrad = 2d array of floats consisting of the gradient\nX = 2d array of floats consisting of the row covariates, with all  categorical variables coded in appropriate contrasts\nY = 2d array of floats consisting of the multivariate response observations\nZ = 2d array of floats consisting of the column covariates, with all  categorical variables coded in appropriate contrasts\nnorms = nothing\nlambdaL1 = l1 penalty, a floating scalar\nlambdaL2 = l2 penalty, a floating scalar\nreg = 2d array of bits, indicating whether or not to regularize each of the  coefficients\niter = 1d array consisting of a single integer keeping track of how many  iterations have been computed\nstepsize = 1d array consisting of a float; step size of updates\n\nValue\n\nNone; updates coefficients in place\n\n\n\n\n\n","category":"method"},{"location":"functions/#MatrixLMnet.update_fista2!-Tuple{AbstractMatrix{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}, Float64, Float64, BitMatrix, AbstractVector{Float64}}","page":"Types and Functions","title":"MatrixLMnet.update_fista2!","text":"update_fista2!(B::AbstractArray{Float64,2}, \n                    A::AbstractArray{Float64,2}, \n                    resid_B::AbstractArray{Float64,2}, \n                    grad::AbstractArray{Float64,2}, \n                    X::AbstractArray{Float64,2}, \n                    Y::AbstractArray{Float64,2}, \n                    Z::AbstractArray{Float64,2}, \n                    norms::AbstractArray{Float64,2}, \n                    lambdaL1::Float64, lambdaL2::Float64, \n                    reg::BitArray{2}, \n                    stepsize::AbstractArray{Float64,1})\n\nUpdates coefficient estimates in place for each FISTA iteration when X and  Z are not standardized, but without updating the extrapolated coefficients. \n\nArguments\n\nB = 2d array of floats consisting of coefficient estimates\nA = 2d array of floats consisting of extrapolated coefficients \nresid_B = 2d array of floats consisting of the residuals calculated from  the coefficient estimates\ngrad = 2d array of floats consisting of the gradient\nX = 2d array of floats consisting of the row covariates, with all  categorical variables coded in appropriate contrasts\nY = 2d array of floats consisting of the multivariate response observations\nZ = 2d array of floats consisting of the column covariates, with all  categorical variables coded in appropriate contrasts\nnorms = 2d array of floats consisting of the norms corresponding to each  coefficient\nlambda = lambda penalty, a floating scalar\nreg = 2d array of bits, indicating whether or not to regularize each of the  coefficients\nstepsize = 1d array consisting of a float; step size of updates\n\nValue\n\nNone; updates coefficients in place\n\n\n\n\n\n","category":"method"},{"location":"functions/#MatrixLMnet.update_fista2!-Tuple{AbstractMatrix{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}, Nothing, Float64, Float64, BitMatrix, AbstractVector{Float64}}","page":"Types and Functions","title":"MatrixLMnet.update_fista2!","text":"update_fista2!(B::AbstractArray{Float64,2}, \n                    A::AbstractArray{Float64,2}, \n                    resid_B::AbstractArray{Float64,2}, \n                    grad::AbstractArray{Float64,2}, \n                    X::AbstractArray{Float64,2}, \n                    Y::AbstractArray{Float64,2}, \n                    Z::AbstractArray{Float64,2}, \n                    norms::Nothing, lambdaL1::Float64, lambdaL2::Float64,\n                    reg::BitArray{2}, \n                    stepsize::AbstractArray{Float64,1})\n\nUpdates coefficient estimates in place for each FISTA iteration when X and  Z are both standardized, but without updating the extrapolated coefficients. \n\nArguments\n\nB = 2d array of floats consisting of coefficient estimates\nA = 2d array of floats consisting of extrapolated coefficients \nresid_B = 2d array of floats consisting of the residuals calculated from  the coefficient estimates\ngrad = 2d array of floats consisting of the gradient\nX = 2d array of floats consisting of the row covariates, with all  categorical variables coded in appropriate contrasts\nY = 2d array of floats consisting of the multivariate response observations\nZ = 2d array of floats consisting of the column covariates, with all  categorical variables coded in appropriate contrasts\nnorms = nothing\nlambdaL1 = l1 penalty, a floating scalar\nlambdaL2 = l2 penalty, a floating scalar\nreg = 2d array of bits, indicating whether or not to regularize each of the  coefficients\nstepsize = 1d array consisting of a float; step size of updates\n\nValue\n\nNone; updates coefficients in place\n\n\n\n\n\n","category":"method"},{"location":"functions/#MatrixLMnet.update_ista!-Tuple{AbstractMatrix{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}, Float64, Float64, BitMatrix, AbstractVector{Float64}}","page":"Types and Functions","title":"MatrixLMnet.update_ista!","text":"update_istaNet!(B::AbstractArray{Float64,2}, \n                  resid::AbstractArray{Float64,2}, \n                  grad::AbstractArray{Float64,2}, \n                  X::AbstractArray{Float64,2}, \n                  Y::AbstractArray{Float64,2}, \n                  Z::AbstractArray{Float64,2}, \n                  norms::AbstractArray{Float64,2}, \n                  lambdaL1::Float64, lambdaL2::Float64, reg::BitArray{2}, \n                  stepsize::AbstractArray{Float64,1})\n\nUpdates coefficient estimates in place for each ISTA iteration based on the Elastic-net solution, when X and Z are not standardized. \n\nArguments\n\nB = 2d array of floats consisting of coefficient estimates\nresid = 2d array of floats consisting of the residuals\ngrad = 2d array of floats consisting of the gradient\nX = 2d array of floats consisting of the row covariates, with all  categorical variables coded in appropriate contrasts\nY = 2d array of floats consisting of the multivariate response observations\nZ = 2d array of floats consisting of the column covariates, with all  categorical variables coded in appropriate contrasts\nnorms = 2d array of floats consisting of the norms corresponding to each  coefficient\nlambdaL1 =  penalty, a floating scalar\nlambdaL2 =  penalty, a floating scalar\nreg = 2d array of bits, indicating whether or not to regularize each of the  coefficients\nstepsize = 1d array consisting of a float; step size of updates\n\nValue\n\nNone; updates coefficients in place\n\n\n\n\n\n","category":"method"},{"location":"functions/#MatrixLMnet.update_ista!-Tuple{AbstractMatrix{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}, AbstractMatrix{Float64}, Nothing, Float64, Float64, BitMatrix, AbstractVector{Float64}}","page":"Types and Functions","title":"MatrixLMnet.update_ista!","text":"update_istaNet!(B::AbstractArray{Float64,2}, \n                  resid::AbstractArray{Float64,2}, \n                  grad::AbstractArray{Float64,2}, \n                  X::AbstractArray{Float64,2}, \n                  Y::AbstractArray{Float64,2}, \n                  Z::AbstractArray{Float64,2}, \n                  norms::Nothing, lambdaL1::Float64, lambdaL2::Float64, \n                  reg::BitArray{2}, \n                  stepsize::AbstractArray{Float64,1})\n\nUpdates coefficient estimates in place for each ISTA iteration based on the Elastic-net  solution, when X and Z are both standardized. \n\nArguments\n\nB = 2d array of floats consisting of coefficient estimates\nresid = 2d array of floats consisting of the residuals\ngrad = 2d array of floats consisting of the gradient\nX = 2d array of floats consisting of the row covariates, with all  categorical variables coded in appropriate contrasts\nY = 2d array of floats consisting of the multivariate response observations\nZ = 2d array of floats consisting of the column covariates, with all  categorical variables coded in appropriate contrasts\nnorms = nothing\nlambdaL1 =  l1 penalty, a floating scalar\nlambdaL1 =  l2 penalty, a floating scalar\nreg = 2d array of bits, indicating whether or not to regularize each of the  coefficients\nstepsize = 1d array consisting of a float; step size of updates\n\nValue\n\nNone; updates coefficients in place\n\n\n\n\n\n","category":"method"},{"location":"functions/#MatrixLMnet.valid_reduce2","page":"Types and Functions","title":"MatrixLMnet.valid_reduce2","text":"valid_reduce2(A::Array{Float64,3}, fun::Function=mean)\n\nReduce a 2d matrix across its columns using a given function, but ignoring  NaN, Inf, and -Inf. \n\nArguments\n\nA = 2d array of floats\nfun = function with which to reduce across the columns of A\n\nValue\n\n2d array of floats\n\n\n\n\n\n","category":"function"},{"location":"MLMnet_Simulation/#Overview","page":"Getting Started","title":"Overview","text":"","category":"section"},{"location":"MLMnet_Simulation/","page":"Getting Started","title":"Getting Started","text":"MatrixLMnet.jl is a comprehensive package for both L_1 and L_2 penalized estimation in matrix linear models.    It offers efficient and versatile methods for fitting sparse matrix linear models, particularly for analyzing structured high-throughput data. In this demonstration, we will explore the functionalities of this package through an easy-to-follow simulation study, showcasing its practical applications and user-friendly features.    ","category":"page"},{"location":"MLMnet_Simulation/","page":"Getting Started","title":"Getting Started","text":"Within the scope of the matrix linear model framework, the model is articulated as follows:   ","category":"page"},{"location":"MLMnet_Simulation/","page":"Getting Started","title":"Getting Started","text":"Y = XBZ^T+E","category":"page"},{"location":"MLMnet_Simulation/","page":"Getting Started","title":"Getting Started","text":"Where     ","category":"page"},{"location":"MLMnet_Simulation/","page":"Getting Started","title":"Getting Started","text":"Y_n times m is the response matrix,   \nX_n times p is the matrix for main predictors,   \nZ_m times q denote the response attributes matrix based on a supervised knowledge,   \nE_n times m is the error term,   \nB_p times q is the matrix for main and interaction effects.,","category":"page"},{"location":"MLMnet_Simulation/#Data-Generation","page":"Getting Started","title":"Data Generation","text":"","category":"section"},{"location":"MLMnet_Simulation/","page":"Getting Started","title":"Getting Started","text":"using MatrixLMnet\nusing DataFrames\nusing Plots","category":"page"},{"location":"MLMnet_Simulation/","page":"Getting Started","title":"Getting Started","text":"In this example,  we set up a simulation for matrix linear models.  We generate a dataset containing two categorical variables and four numerical variables.","category":"page"},{"location":"MLMnet_Simulation/","page":"Getting Started","title":"Getting Started","text":"# Define number of samples in the predictors dataset\nn = 100\n\n# Generate data with one categorical variables and 3 numerical variables.\ndfX = hcat(DataFrame(\n    catvar1=rand([\"A\", \"B\", \"C\", \"D\"], n)), \n    DataFrame(rand(n,3), [\"numvar1\", \"numvar2\", \"numvar3\"]));\n\nfirst(dfX, 3)","category":"page"},{"location":"MLMnet_Simulation/","page":"Getting Started","title":"Getting Started","text":"<div><div style = \"float: left;\"><span>3×4 DataFrame</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">catvar1</th><th style = \"text-align: left;\">numvar1</th><th style = \"text-align: left;\">numvar2</th><th style = \"text-align: left;\">numvar3</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"String\" style = \"text-align: left;\">String</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: left;\">A</td><td style = \"text-align: right;\">0.0272858</td><td style = \"text-align: right;\">0.880826</td><td style = \"text-align: right;\">0.284163</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: left;\">B</td><td style = \"text-align: right;\">0.571666</td><td style = \"text-align: right;\">0.414586</td><td style = \"text-align: right;\">0.406994</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: left;\">A</td><td style = \"text-align: right;\">0.151188</td><td style = \"text-align: right;\">0.680321</td><td style = \"text-align: right;\">0.424177</td></tr></tbody></table></div>","category":"page"},{"location":"MLMnet_Simulation/","page":"Getting Started","title":"Getting Started","text":"We need to create a design matrix X form the dataframe dfX. We can use the design_matrix() function from the package MatrixLM.jl. For more information about its usage and the macro @mlmformula please refer to its documentation.       First, we need to select the contrast coding of our categorical variable.","category":"page"},{"location":"MLMnet_Simulation/","page":"Getting Started","title":"Getting Started","text":"# Define constrast coding for catvar \nlevels_catvar1 = sort(unique(dfX.catvar1));\nX_ctrst = Dict(\n             :catvar1 => MatrixLMnet.MatrixLM.StatsModels.DummyCoding(levels = levels_catvar1),\n           );","category":"page"},{"location":"MLMnet_Simulation/","page":"Getting Started","title":"Getting Started","text":"Let convert the dataframe dfX to the predictor matrix X using design_matrix():","category":"page"},{"location":"MLMnet_Simulation/","page":"Getting Started","title":"Getting Started","text":"X = design_matrix(@mlmformula(1 + catvar1 + numvar1 + numvar2 + numvar3), dfX, X_ctrst);","category":"page"},{"location":"MLMnet_Simulation/","page":"Getting Started","title":"Getting Started","text":"We also define Z, a random matrix with dimensions m by q, and B, a matrix of random integers between -5 and 5 with dimensions matching X and Z. According the matrix linear models framework, the response matrix Y is calculated as the product of X, B, and the transpose of Z, with an added noise matrix E.     Finally, we construct a RawData object named dat`, which comprises the response matrix Y and the predictor matrices X and Z.","category":"page"},{"location":"MLMnet_Simulation/","page":"Getting Started","title":"Getting Started","text":"# Number of predictors\np = size(X)[2]\n# Number of column responses\nm = 250\n# Number of column covariates\nq = 20\n\nZ = rand(m,q)\nB = rand(-5:5,p,q)\nE = randn(n,m)\nY = X*B*transpose(Z)+E\n\n# Construct a RawData object\ndat = RawData(Response(Y), Predictors(X, Z));","category":"page"},{"location":"MLMnet_Simulation/#Model-Estimation","page":"Getting Started","title":"Model Estimation","text":"","category":"section"},{"location":"MLMnet_Simulation/#Hyper-parameters","page":"Getting Started","title":"Hyper parameters","text":"","category":"section"},{"location":"MLMnet_Simulation/","page":"Getting Started","title":"Getting Started","text":"Create a 1d array of lambda penalties values to fit the estimates. If the lambdas are not in descending order, they will be automatically sorted by mlmnet.","category":"page"},{"location":"MLMnet_Simulation/","page":"Getting Started","title":"Getting Started","text":"lambdas = reverse(1.5.^(1:3:10))","category":"page"},{"location":"MLMnet_Simulation/","page":"Getting Started","title":"Getting Started","text":"4-element Vector{Float64}:\n 57.6650390625\n 17.0859375\n  5.0625\n  1.5","category":"page"},{"location":"MLMnet_Simulation/","page":"Getting Started","title":"Getting Started","text":"Create a 1d array of alpha parameter penalties values that determine the penalties mix between L_1 and L_2 to fit the estimates according to the Elastic Net penalization method.  In the case of Lasso regression (L_1 regularization), alpha should be 1, and 0 for Ridge regression (L_2 regularization). If the alphas are not in descending order, they will be automatically sorted by mlmnet.","category":"page"},{"location":"MLMnet_Simulation/","page":"Getting Started","title":"Getting Started","text":"alphas = reverse(collect(0:0.5:1));","category":"page"},{"location":"MLMnet_Simulation/","page":"Getting Started","title":"Getting Started","text":"If alphas argument is omitted, a Lasso regression will be applied which is equivalent to alphas = [1].  ","category":"page"},{"location":"MLMnet_Simulation/#Elastic-Net-penalization-algorithms-selection","page":"Getting Started","title":"Elastic Net penalization algorithms selection","text":"","category":"section"},{"location":"MLMnet_Simulation/","page":"Getting Started","title":"Getting Started","text":"The algorithms available for fitting Elastic Net penalized estimates in mlmnet function come with customizable keyword arguments for fine-tuning.  The method keyword argument selects the function implementing the Elastic-net penalty estimation method. The default method is ista; alternative options include fista, fista_bt, admm, and cd.     Note: Any irrelevant arguments will simply be disregarded.","category":"page"},{"location":"MLMnet_Simulation/","page":"Getting Started","title":"Getting Started","text":"Algorithm Methods Parameter Default Description\nCoordinate Descent \"cd\" isRandom true Determines the use of either random or cyclic updates\nActive Coordinate Descent \"cd_active\" isRandom true Specifies the choice between random and cyclic updates\nISTA with fixed step size \"ista\" stepsize 0.01 Sets a fixed step size for updates\n  setStepsize true Decides if the fixed step size is to be computed, overriding stepsize\nFISTA with fixed step size \"fista\" stepsize 0.01 Establishes a fixed step size for updates\n  setStepsize true Determines if the fixed step size should be recalculated, overriding stepsize\nFISTA with backtracking \"fista_bt\" stepsize 0.01 Indicates the initial step size for updates\n  gamma 0.5 The multiplier for step size during backtracking/line search\nADMM \"admm\" rho 1.0 The parameter influencing ADMM tuning\n  setRho true Decides whether the ADMM tuning parameter rho is to be auto-calculated\n  tau_incr 2.0 The factor for increasing the ADMM tuning parameter\n  tau_decr 2.0 The factor for decreasing the ADMM tuning parameter\n  mu 10.0 The parameter influencing the balance between primal and dual residuals","category":"page"},{"location":"MLMnet_Simulation/#Estimation","page":"Getting Started","title":"Estimation","text":"","category":"section"},{"location":"MLMnet_Simulation/","page":"Getting Started","title":"Getting Started","text":"In this example, we will use the 'fista' method for our estimation process.  Given that our design matrix already incorporates an intercept, we specify that there is no need to add an additional intercept to the design matrices X and Z.","category":"page"},{"location":"MLMnet_Simulation/","page":"Getting Started","title":"Getting Started","text":"est_fista = mlmnet(\n    dat, \n    [lambdas[1]], [alphas[1]], \n    method = \"fista\", \n    addZIntercept = false, addXIntercept = false, isVerbose = false);","category":"page"},{"location":"MLMnet_Simulation/","page":"Getting Started","title":"Getting Started","text":"Let's delve into the structure returned by the mlmnet() function. The result, est_fista, is of the Mlmnet type, a structured data type encompassing the next key fields:","category":"page"},{"location":"MLMnet_Simulation/","page":"Getting Started","title":"Getting Started","text":"B: This is the estimated coefficient matrix. It is a four-dimensional matrix where the dimensions represent rows, columns, lambda indices, and alpha indices.\nlambdas: A vector containing the lambda values utilized in the estimation.\nalphas: A vector of the alpha values used.\ndata: A RawData object that holds the original dataset used for the estimation.","category":"page"},{"location":"MLMnet_Simulation/","page":"Getting Started","title":"Getting Started","text":"For instance, let execute the command with all lambdas and alphas values:","category":"page"},{"location":"MLMnet_Simulation/","page":"Getting Started","title":"Getting Started","text":"est_fista = mlmnet(\n    dat, \n    lambdas, alphas, \n    method = \"fista\", \n    addZIntercept = false, addXIntercept = false, isVerbose = false);","category":"page"},{"location":"MLMnet_Simulation/","page":"Getting Started","title":"Getting Started","text":"In this case, the matrix B would have dimensions of (7, 20, 4, 3). These dimensions correspond to the estimated coefficients across each of the 4 lambda values and 3 alpha values, offering a comprehensive view of the coefficient variations influenced by different regularization parameters.","category":"page"},{"location":"MLMnet_Simulation/#Cross-Validation","page":"Getting Started","title":"Cross Validation","text":"","category":"section"},{"location":"MLMnet_Simulation/","page":"Getting Started","title":"Getting Started","text":"Cross-validation within the mlmnet framework is implemented by the mlmnet_cv function. This function offers flexibility in defining the folds for cross-validation. We can either specify the row and column folds of Y manually as 1D arrays containing row or column indices, or we can simply specify the desired number of folds. When a specific number of folds is indicated, mlmnet_cv will generate disjoint folds of approximately equal size using the make_folds function. Setting the number of row or column folds to 1 implies the use of all rows or columns of Y in each fold.","category":"page"},{"location":"MLMnet_Simulation/","page":"Getting Started","title":"Getting Started","text":"One key benefit of manually inputting row and/or column folds is the user's ability to stratify or control the nature of the folds. For instance, make_folds_conds can be employed to create folds based on a set of categorical conditions, ensuring each condition is equally represented across folds. Additionally, cross-validation computations are executed in parallel whenever feasible, enhancing efficiency. To incorporate non-standard behaviors in mlmnet, we can pass the relevant keyword arguments directly into mlmnet_cv.","category":"page"},{"location":"MLMnet_Simulation/","page":"Getting Started","title":"Getting Started","text":"In the following call, mlmnet_cv is configured to create 10 disjoint row folds while utilizing all columns of Y in each fold, as denoted by the 1:","category":"page"},{"location":"MLMnet_Simulation/","page":"Getting Started","title":"Getting Started","text":"est_fista_cv = mlmnet_cv(\n    dat, \n    lambdas, alphas,\n    10, 1, \n    method = \"fista\",  \n    addZIntercept = false, addXIntercept = false, isVerbose = false);","category":"page"},{"location":"MLMnet_Simulation/","page":"Getting Started","title":"Getting Started","text":"Note: The dig keyword argument in mlmnet_cv is used to set the precision level for computing the percentage of zero coefficients. Its default value is 12, allowing for detailed precision in the calculations.","category":"page"},{"location":"MLMnet_Simulation/","page":"Getting Started","title":"Getting Started","text":"The function returns an Mlmnet_cv object, which contains an array of the Mlmnet objects for each fold (MLMNets); the lambda penalty values used (lambdas); the row and column folds (rowFolds and colFolds); an array of the mean-squared error for each fold (mse); and an array of the proportion of zero interaction effects for each fold (propZero). The keyword argument dig in mlmnet_cv adjusts the level of precision when calculating the percent of zero coefficients. It defaults to 12.","category":"page"},{"location":"MLMnet_Simulation/","page":"Getting Started","title":"Getting Started","text":"The output from the mlmnet_cv() function yields an Mlmnet_cv object. This object encompasses the following components:","category":"page"},{"location":"MLMnet_Simulation/","page":"Getting Started","title":"Getting Started","text":"MLMNets: An array consisting of the Mlmnet objects corresponding to each fold.\nlambdas: The array of lambda penalty values applied during the estimati\nalphas: The array of alpha penalty values applied during the estimation.on.\nrowFolds and colFolds: Arrays representing the row and column folds used in cross-validation.\nmse: An array detailing the mean-squared error for each individual fold.\npropZero: An array capturing the proportion of zero interaction effects in each ft 12.\"","category":"page"},{"location":"MLMnet_Simulation/","page":"Getting Started","title":"Getting Started","text":"mlmnet_cv_summary presents a table summarizing the average mean-squared error (MSE) and the proportion of zero coefficients for each pair of (lambda, alpha) values across all folds. The optimal (lambda, alpha) could be selected as the one that minimizes the MSE. Alternatively, it might be chosen according to a specific, pre-defined proportion of zeros desired in the coefficient estimates.","category":"page"},{"location":"MLMnet_Simulation/","page":"Getting Started","title":"Getting Started","text":"mlmnet_cv_summary(est_fista_cv)","category":"page"},{"location":"MLMnet_Simulation/","page":"Getting Started","title":"Getting Started","text":"<div><div style = \"float: left;\"><span>12×6 DataFrame</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">𝜆_𝛼_Index</th><th style = \"text-align: left;\">Lambda</th><th style = \"text-align: left;\">Alpha</th><th style = \"text-align: left;\">AvgMSE</th><th style = \"text-align: left;\">StdMSE</th><th style = \"text-align: left;\">AvgPropZero</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"Tuple{Int64, Int64}\" style = \"text-align: left;\">Tuple…</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: left;\">(1, 1)</td><td style = \"text-align: right;\">57.665</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">18.7416</td><td style = \"text-align: right;\">1.87917</td><td style = \"text-align: right;\">0.679286</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: left;\">(2, 1)</td><td style = \"text-align: right;\">17.0859</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">6.46943</td><td style = \"text-align: right;\">0.57586</td><td style = \"text-align: right;\">0.42</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: left;\">(3, 1)</td><td style = \"text-align: right;\">5.0625</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">2.49412</td><td style = \"text-align: right;\">0.290205</td><td style = \"text-align: right;\">0.178571</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: left;\">(4, 1)</td><td style = \"text-align: right;\">1.5</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">1.22069</td><td style = \"text-align: right;\">0.071585</td><td style = \"text-align: right;\">0.0671429</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5</td><td style = \"text-align: left;\">(1, 2)</td><td style = \"text-align: right;\">57.665</td><td style = \"text-align: right;\">0.5</td><td style = \"text-align: right;\">32006.4</td><td style = \"text-align: right;\">3798.02</td><td style = \"text-align: right;\">0.0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">6</td><td style = \"text-align: left;\">(2, 2)</td><td style = \"text-align: right;\">17.0859</td><td style = \"text-align: right;\">0.5</td><td style = \"text-align: right;\">6609.07</td><td style = \"text-align: right;\">862.572</td><td style = \"text-align: right;\">0.0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">7</td><td style = \"text-align: left;\">(3, 2)</td><td style = \"text-align: right;\">5.0625</td><td style = \"text-align: right;\">0.5</td><td style = \"text-align: right;\">829.012</td><td style = \"text-align: right;\">123.063</td><td style = \"text-align: right;\">0.005</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">8</td><td style = \"text-align: left;\">(4, 2)</td><td style = \"text-align: right;\">1.5</td><td style = \"text-align: right;\">0.5</td><td style = \"text-align: right;\">92.8234</td><td style = \"text-align: right;\">14.5585</td><td style = \"text-align: right;\">0.005</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">9</td><td style = \"text-align: left;\">(1, 3)</td><td style = \"text-align: right;\">57.665</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">61511.1</td><td style = \"text-align: right;\">7044.65</td><td style = \"text-align: right;\">0.0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">10</td><td style = \"text-align: left;\">(2, 3)</td><td style = \"text-align: right;\">17.0859</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">18196.8</td><td style = \"text-align: right;\">2234.07</td><td style = \"text-align: right;\">0.0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">11</td><td style = \"text-align: left;\">(3, 3)</td><td style = \"text-align: right;\">5.0625</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">2839.32</td><td style = \"text-align: right;\">390.58</td><td style = \"text-align: right;\">0.0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">12</td><td style = \"text-align: left;\">(4, 3)</td><td style = \"text-align: right;\">1.5</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">320.418</td><td style = \"text-align: right;\">49.9818</td><td style = \"text-align: right;\">0.0</td></tr></tbody></table></div>","category":"page"},{"location":"MLMnet_Simulation/","page":"Getting Started","title":"Getting Started","text":"The lambda_min function returns the summary information for the lambdas that correspond to the minimum average test MSE across folds and the MSE that is one standard error greater.","category":"page"},{"location":"MLMnet_Simulation/","page":"Getting Started","title":"Getting Started","text":"lambda_min(est_fista_cv)","category":"page"},{"location":"MLMnet_Simulation/","page":"Getting Started","title":"Getting Started","text":"<div><div style = \"float: left;\"><span>2×6 DataFrame</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">Name</th><th style = \"text-align: left;\">Index</th><th style = \"text-align: left;\">Lambda</th><th style = \"text-align: left;\">Alpha</th><th style = \"text-align: left;\">AvgMSE</th><th style = \"text-align: left;\">AvgPropZero</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"String\" style = \"text-align: left;\">String</th><th title = \"Tuple{Int64, Int64}\" style = \"text-align: left;\">Tuple…</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: left;\">(𝜆, 𝛼)_min</td><td style = \"text-align: left;\">(4, 1)</td><td style = \"text-align: right;\">1.5</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">1.22069</td><td style = \"text-align: right;\">0.0671429</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: left;\">(𝜆, 𝛼)_min1se</td><td style = \"text-align: left;\">(4, 1)</td><td style = \"text-align: right;\">1.5</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">1.22069</td><td style = \"text-align: right;\">0.0671429</td></tr></tbody></table></div>","category":"page"},{"location":"MLMnet_Simulation/#Model-predictions-and-residuals","page":"Getting Started","title":"Model predictions and residuals","text":"","category":"section"},{"location":"MLMnet_Simulation/","page":"Getting Started","title":"Getting Started","text":"The 4D array of coefficient estimates is returned by the function coef(est), where est is the results of the function mlmnet. ","category":"page"},{"location":"MLMnet_Simulation/","page":"Getting Started","title":"Getting Started","text":"The command est_fista.B or coef(est_fista) retrieves the full array containing the estimated coefficients.     Let display the residual errors heatmap based on our estimation.","category":"page"},{"location":"MLMnet_Simulation/","page":"Getting Started","title":"Getting Started","text":"To compare the estimated coefficients with the original matrix B, we will visualize the matrices using heatmaps. This graphical representation allows us to readily see differences and similarities between the two.","category":"page"},{"location":"MLMnet_Simulation/","page":"Getting Started","title":"Getting Started","text":"plot(\n    heatmap(B[end:-1:1, :], \n            size = (800, 300)),     \n    heatmap(est_fista.B[end:-1:1, :, 4, 1], \n            size = (800, 300)), \n            # clims = (-5, 5)),     \n    title = [\"\\$ \\\\mathbf{B}\\$\" \"\\$ \\\\mathbf{\\\\hat{B}}\\$\"]\n)","category":"page"},{"location":"MLMnet_Simulation/","page":"Getting Started","title":"Getting Started","text":"(Image: svg)","category":"page"},{"location":"MLMnet_Simulation/","page":"Getting Started","title":"Getting Started","text":"To obtain predicted values and residuals, one can use predict and resid respectively.  By default, these functions use the data from the model fit, but alternative data can be supplied: newPredictors (a Predictors object) for predict, and newData (a RawData object) for resid. For added convenience, fitted(est) returns the fitted values by default when calling predict.","category":"page"},{"location":"MLMnet_Simulation/","page":"Getting Started","title":"Getting Started","text":"Let's employ the same visualization method to compare the predicted values with the original Y response matrix. This allows us to gauge the accuracy of our model predictions.","category":"page"},{"location":"MLMnet_Simulation/","page":"Getting Started","title":"Getting Started","text":"preds = predict(est_fista, lambdas[4], alphas[1]); # Prediction value","category":"page"},{"location":"MLMnet_Simulation/","page":"Getting Started","title":"Getting Started","text":"plot(\n    heatmap(Y[end:-1:1, :], \n            size = (800, 300)),     \n    heatmap(preds[end:-1:1, :], \n            size = (800, 300), \n            clims = (-25, 45)\n            ),     \n    title = [\"\\$ \\\\mathbf{Y}\\$\" \"\\$ \\\\mathbf{\\\\hat{Y}}\\$\"],\n)","category":"page"},{"location":"MLMnet_Simulation/","page":"Getting Started","title":"Getting Started","text":"(Image: svg)","category":"page"},{"location":"MLMnet_Simulation/","page":"Getting Started","title":"Getting Started","text":"The resid() function provides us with the ability to compute residuals for each observation, helping you evaluate the discrepancy between the model's predictions and the actual data.","category":"page"},{"location":"MLMnet_Simulation/","page":"Getting Started","title":"Getting Started","text":"resids= resid(est_fista, lambdas[4], alphas[1]); ","category":"page"},{"location":"MLMnet_Simulation/","page":"Getting Started","title":"Getting Started","text":"plot(\n    heatmap(\n        resids[end:-1:1, :], \n        color = cgrad(:bluesreds,[0.1, 0.3, 0.7, 0.9], alpha = 0.8),\n        title = \"Residual errors\",\n        titlefontsize = 12, grid = false,\n        xlabel = \"Responses\",\n        ylabel = \"Samples\",\n        size = (500, 250),\n        left_margin = (5,:mm), bottom_margin = (5,:mm),\n    ),\n    histogram(\n        (reshape(resids,250*100,1)),\n        grid  = false,\n        label = \"\",\n        size = (800, 300)\n    ),     \n    title = [\"Residuals\" \"Distribution of the residuals\"]\n)","category":"page"},{"location":"MLMnet_Simulation/","page":"Getting Started","title":"Getting Started","text":"(Image: svg)","category":"page"},{"location":"MLMnet_Simulation/","page":"Getting Started","title":"Getting Started","text":"Additional details can be found in the documentation for specific functions.","category":"page"},{"location":"#MatrixLMnet:-Core-functions-for-penalized-estimation-for-matrix-linear-models.","page":"Home","title":"MatrixLMnet: Core functions for penalized estimation for matrix linear models.","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"(Image: CI) (Image: codecov)","category":"page"},{"location":"","page":"Home","title":"Home","text":"Package for L_1 and L_2 penalized estimation of  matrix linear models (bilinear models for matrix-valued data).","category":"page"},{"location":"","page":"Home","title":"Home","text":"MatrixLMnet depends on the MatrixLM package,  which provides core functions for closed-form least squares estimates for matrix linear models. ","category":"page"},{"location":"","page":"Home","title":"Home","text":"See the paper, \"Sparse matrix linear models for structured high-throughput data\", and its reproducible code for details on the L1 penalized estimation.","category":"page"},{"location":"#Installation","page":"Home","title":"Installation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The MatrixLMnet package can be installed by running: ","category":"page"},{"location":"","page":"Home","title":"Home","text":"using Pkg\nPkg.add(\"MatrixLMnet\")","category":"page"},{"location":"","page":"Home","title":"Home","text":"For the most recent version, use:","category":"page"},{"location":"","page":"Home","title":"Home","text":"using Pkg\nPkg.add(url = \"https://github.com/senresearch/MatrixLMnet.jl\", rev=\"main\")","category":"page"},{"location":"","page":"Home","title":"Home","text":"Alternatively, you can also install MatrixLMnet from the julia REPL. Press ] to enter pkg mode again, and enter the following:","category":"page"},{"location":"","page":"Home","title":"Home","text":"add MatrixLMnet","category":"page"},{"location":"#Contributing","page":"Home","title":"Contributing","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"We appreciate contributions from users including reporting bugs, fixing issues, improving performance and adding new features.","category":"page"},{"location":"#Questions","page":"Home","title":"Questions","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"If you have questions about contributing or using MatrixLMnet package, please communicate with authors form github.","category":"page"},{"location":"#Citing-MatrixLMnet","page":"Home","title":"Citing MatrixLMnet","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"If you use MatrixLMnet in a scientific publication, please consider citing following paper:","category":"page"},{"location":"","page":"Home","title":"Home","text":"Jane W. Liang. Śaunak Sen. \"Sparse matrix linear models for structured high-throughput data.\" Ann. Appl. Stat. 16 (1) 169 - 192, March 2022. https://doi.org/10.1214/21-AOAS1444","category":"page"},{"location":"","page":"Home","title":"Home","text":"@article{10.1214/21-AOAS1444,\nauthor = {Jane W. Liang and Śaunak Sen},\ntitle = {{Sparse matrix linear models for structured high-throughput data}},\nvolume = {16},\njournal = {The Annals of Applied Statistics},\nnumber = {1},\npublisher = {Institute of Mathematical Statistics},\npages = {169 -- 192},\nkeywords = {ADMM, FISTA, gradient descent, Julia, Lasso, proximal gradient algorithms},\nyear = {2022},\ndoi = {10.1214/21-AOAS1444},\nURL = {https://doi.org/10.1214/21-AOAS1444}\n}","category":"page"}]
}
